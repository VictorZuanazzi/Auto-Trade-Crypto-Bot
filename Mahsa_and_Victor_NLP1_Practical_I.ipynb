{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mahsa and Victor NLP1 Practical I",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorZuanazzi/Auto-Trade-Crypto-Bot/blob/master/Mahsa_and_Victor_NLP1_Practical_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lIZrAUx57vsM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Practical 1: Sentiment Detection of Movie Reviews\n",
        "========================================\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "J4kXPMhyngZW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This practical concerns sentiment detection of movie reviews.\n",
        "In [this file](https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json) (80MB) you will find 1000 positive and 1000 negative **movie reviews**.\n",
        "Each review is a **document** and consists of one or more sentences.\n",
        "\n",
        "To prepare yourself for this practical, you should\n",
        "have a look at a few of these texts to understand the difficulties of\n",
        "the task (how might one go about classifying the texts?); you will write\n",
        "code that decides whether a random unseen movie review is positive or\n",
        "negative.\n",
        "\n",
        "Please make sure you have read the following paper:\n",
        "\n",
        ">   Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan\n",
        "(2002). \n",
        "[Thumbs up? Sentiment Classification using Machine Learning\n",
        "Techniques](https://dl.acm.org/citation.cfm?id=1118704). EMNLP.\n",
        "\n",
        "Bo Pang et al. were the \"inventors\" of the movie review sentiment\n",
        "classification task, and the above paper was one of the first papers on\n",
        "the topic. The first version of your sentiment classifier will do\n",
        "something similar to Bo Pang’s system. If you have questions about it,\n",
        "we should resolve them in our first demonstrated practical.\n"
      ]
    },
    {
      "metadata": {
        "id": "cb7errgRASzZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Advice**\n",
        "\n",
        "Please read through the entire practical and familiarise\n",
        "yourself with all requirements before you start coding or otherwise\n",
        "solving the tasks. Writing clean and concise code can make the difference\n",
        "between solving the assignment in a matter of hours, and taking days to\n",
        "run all experiments.\n",
        "\n",
        "**Environment**\n",
        "\n",
        "All code should be written in **Python 3**. \n",
        "If you use Colab, check if you have that version with `Runtime -> Change runtime type` in the top menu.\n",
        "\n",
        "> If you want to work in your own computer, then download this notebook through `File -> Download .ipynb`.\n",
        "The easiest way to\n",
        "install Python is through downloading\n",
        "[Anaconda](https://www.anaconda.com/download). \n",
        "After installation, you can start the notebook by typing `jupyter notebook filename.ipynb`.\n",
        "You can also use an IDE\n",
        "such as [PyCharm](https://www.jetbrains.com/pycharm/download/) to make\n",
        "coding and debugging easier. It is good practice to create a [virtual\n",
        "environment](https://docs.python.org/3/tutorial/venv.html) for this\n",
        "project, so that any Python packages don’t interfere with other\n",
        "projects.\n",
        "\n",
        "#### Learning Python 3\n",
        "\n",
        "If you are new to Python 3, you may want to check out a few of these resources:\n",
        "- https://learnxinyminutes.com/docs/python3/\n",
        "- https://www.learnpython.org/\n",
        "- https://docs.python.org/3/tutorial/"
      ]
    },
    {
      "metadata": {
        "id": "bXWyGHwE-ieQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading the Data\n",
        "-------------------------------------------------------------"
      ]
    },
    {
      "metadata": {
        "id": "lm-rakqtlMOT",
        "colab_type": "code",
        "outputId": "bd1ec19e-bec3-4a25-b65d-4250cdb82801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "cell_type": "code",
      "source": [
        "# download sentiment lexicon\n",
        "!wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
        "# download review data\n",
        "!wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-23 08:14:30--  https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662577 (647K) [text/plain]\n",
            "Saving to: ‘sent_lexicon.1’\n",
            "\n",
            "\rsent_lexicon.1        0%[                    ]       0  --.-KB/s               \rsent_lexicon.1      100%[===================>] 647.05K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2018-11-23 08:14:30 (9.88 MB/s) - ‘sent_lexicon.1’ saved [662577/662577]\n",
            "\n",
            "--2018-11-23 08:14:31--  https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83503869 (80M) [text/plain]\n",
            "Saving to: ‘reviews.json.1’\n",
            "\n",
            "reviews.json.1      100%[===================>]  79.63M  89.0MB/s    in 0.9s    \n",
            "\n",
            "2018-11-23 08:14:33 (89.0 MB/s) - ‘reviews.json.1’ saved [83503869/83503869]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hok-BFu9lGoK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import sys\n",
        "from subprocess import call\n",
        "from nltk import FreqDist\n",
        "from nltk.util import ngrams\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import sklearn as sk\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import json\n",
        "from collections import Counter\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "careEKj-mRpl",
        "colab_type": "code",
        "outputId": "c5978865-7339-43a9-bd10-daa846e321af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        }
      },
      "cell_type": "code",
      "source": [
        "# load reviews into memory\n",
        "# file structure:\n",
        "# [\n",
        "#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n",
        "#  {\"cv\": integer, \"sentiment\": str, \"content\": list} \n",
        "#   ..\n",
        "# ]\n",
        "# where `content` is a list of sentences, \n",
        "# with a sentence being a list of (token, pos_tag) pairs.\n",
        "\n",
        "# For documentation on POS-tags, see \n",
        "# https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf\n",
        "\n",
        "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  reviews = json.load(f)\n",
        "  \n",
        "print(len(reviews))\n",
        "\n",
        "def print_sentence_with_pos(s):\n",
        "  print(s)\n",
        "  print(\" \".join(\"%s/%s\" % (token, pos_tag) for token, pos_tag in s))\n",
        "\n",
        "for i, r in enumerate(reviews):\n",
        "  print(r[\"cv\"], r[\"sentiment\"], len(r[\"content\"]))  # cv, sentiment, num sents\n",
        "  print_sentence_with_pos(r[\"content\"][0])\n",
        "  if i == 4: \n",
        "    break\n",
        "    \n",
        "c = Counter()\n",
        "for review in reviews:\n",
        "  for sentence in review[\"content\"]:\n",
        "    for token, pos_tag in sentence:\n",
        "      c[token.lower()] += 1\n",
        "      \n",
        "print(\"#types\", len(c))\n",
        "\n",
        "print(\"Most common tokens:\")\n",
        "for token, count in c.most_common(25):\n",
        "  print(\"%10s : %8d\" % (token, count))\n",
        "  \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "0 NEG 29\n",
            "[['Two', 'CD'], ['teen', 'JJ'], ['couples', 'NNS'], ['go', 'VBP'], ['to', 'TO'], ['a', 'DT'], ['church', 'NN'], ['party', 'NN'], [',', ','], ['drink', 'NN'], ['and', 'CC'], ['then', 'RB'], ['drive', 'NN'], ['.', '.']]\n",
            "Two/CD teen/JJ couples/NNS go/VBP to/TO a/DT church/NN party/NN ,/, drink/NN and/CC then/RB drive/NN ./.\n",
            "1 NEG 11\n",
            "[['Damn', 'JJ'], ['that', 'IN'], ['Y2K', 'CD'], ['bug', 'NN'], ['.', '.']]\n",
            "Damn/JJ that/IN Y2K/CD bug/NN ./.\n",
            "2 NEG 24\n",
            "[['It', 'PRP'], ['is', 'VBZ'], ['movies', 'NNS'], ['like', 'IN'], ['these', 'DT'], ['that', 'WDT'], ['make', 'VBP'], ['a', 'DT'], ['jaded', 'JJ'], ['movie', 'NN'], ['viewer', 'NN'], ['thankful', 'JJ'], ['for', 'IN'], ['the', 'DT'], ['invention', 'NN'], ['of', 'IN'], ['the', 'DT'], ['Timex', 'NNP'], ['IndiGlo', 'NNP'], ['watch', 'NN'], ['.', '.']]\n",
            "It/PRP is/VBZ movies/NNS like/IN these/DT that/WDT make/VBP a/DT jaded/JJ movie/NN viewer/NN thankful/JJ for/IN the/DT invention/NN of/IN the/DT Timex/NNP IndiGlo/NNP watch/NN ./.\n",
            "3 NEG 19\n",
            "[['QUEST', 'NN'], ['FOR', 'IN'], ['CAMELOT', 'NNP'], ['``', '``'], ['Quest', 'NNP'], ['for', 'IN'], ['Camelot', 'NNP'], [\"''\", \"''\"], ['is', 'VBZ'], ['Warner', 'NNP'], ['Bros.', 'NNP'], [\"'\", 'POS'], ['first', 'JJ'], ['feature-length', 'JJ'], [',', ','], ['fully-animated', 'JJ'], ['attempt', 'NN'], ['to', 'TO'], ['steal', 'VB'], ['clout', 'NN'], ['from', 'IN'], ['Disney', 'NNP'], [\"'s\", 'POS'], ['cartoon', 'NN'], ['empire', 'NN'], [',', ','], ['but', 'CC'], ['the', 'DT'], ['mouse', 'NN'], ['has', 'VBZ'], ['no', 'DT'], ['reason', 'NN'], ['to', 'TO'], ['be', 'VB'], ['worried', 'VBN'], ['.', '.']]\n",
            "QUEST/NN FOR/IN CAMELOT/NNP ``/`` Quest/NNP for/IN Camelot/NNP ''/'' is/VBZ Warner/NNP Bros./NNP '/POS first/JJ feature-length/JJ ,/, fully-animated/JJ attempt/NN to/TO steal/VB clout/NN from/IN Disney/NNP 's/POS cartoon/NN empire/NN ,/, but/CC the/DT mouse/NN has/VBZ no/DT reason/NN to/TO be/VB worried/VBN ./.\n",
            "4 NEG 38\n",
            "[['Synopsis', 'NNPS'], [':', ':'], ['A', 'DT'], ['mentally', 'RB'], ['unstable', 'JJ'], ['man', 'NN'], ['undergoing', 'VBG'], ['psychotherapy', 'NN'], ['saves', 'VBZ'], ['a', 'DT'], ['boy', 'NN'], ['from', 'IN'], ['a', 'DT'], ['potentially', 'RB'], ['fatal', 'JJ'], ['accident', 'NN'], ['and', 'CC'], ['then', 'RB'], ['falls', 'VBZ'], ['in', 'IN'], ['love', 'NN'], ['with', 'IN'], ['the', 'DT'], ['boy', 'NN'], [\"'s\", 'POS'], ['mother', 'NN'], [',', ','], ['a', 'DT'], ['fledgling', 'NN'], ['restauranteur', 'NN'], ['.', '.']]\n",
            "Synopsis/NNPS :/: A/DT mentally/RB unstable/JJ man/NN undergoing/VBG psychotherapy/NN saves/VBZ a/DT boy/NN from/IN a/DT potentially/RB fatal/JJ accident/NN and/CC then/RB falls/VBZ in/IN love/NN with/IN the/DT boy/NN 's/POS mother/NN ,/, a/DT fledgling/NN restauranteur/NN ./.\n",
            "#types 47743\n",
            "Most common tokens:\n",
            "         , :    77842\n",
            "       the :    75948\n",
            "         . :    59027\n",
            "         a :    37583\n",
            "       and :    35235\n",
            "        of :    33864\n",
            "        to :    31601\n",
            "        is :    25972\n",
            "        in :    21563\n",
            "        's :    18043\n",
            "        it :    15904\n",
            "      that :    15820\n",
            "     -rrb- :    11768\n",
            "     -lrb- :    11670\n",
            "        as :    11312\n",
            "      with :    10739\n",
            "       for :     9816\n",
            "       his :     9542\n",
            "      this :     9497\n",
            "      film :     9404\n",
            "        '' :     9282\n",
            "        he :     8804\n",
            "        `` :     8801\n",
            "         i :     8619\n",
            "       but :     8537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E6PWaEoh8B34",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Symbolic approach – sentiment lexicon (2pts)\n",
        "---------------------------------------------------------------------\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JsTSMb6ma4E8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**How** could one automatically classify movie reviews according to their\n",
        "sentiment? \n",
        "\n",
        "If we had access to a **sentiment lexicon**, then there are ways to solve\n",
        "the problem without using Machine Learning. One might simply look up\n",
        "every open-class word in the lexicon, and compute a binary score\n",
        "$S_{binary}$ by counting how many words match either a positive, or a\n",
        "negative word entry in the sentiment lexicon $SLex$.\n",
        "\n",
        "$$S_{binary}(w_1w_2...w_n) = \\sum_{i = 1}^{n}\\text{sgn}(SLex\\big[w_i\\big])$$\n",
        "\n",
        "**Threshold.** In average there are more positive than negative words per review (~7.13 more positive than negative per review) to take this bias into account you should use a threshold of **8** (roughly the bias itself) to make it harder to classify as positive.\n",
        "\n",
        "$$\n",
        "\\text{classify}(S_{binary}(w_1w_2...w_n)) = \\bigg\\{\\begin{array}{ll}\n",
        "        \\text{positive} & \\text{if } S_{binary}(w_1w_2...w_n) > threshold\\\\\n",
        "        \\text{negative} & \\text{else }\n",
        "        \\end{array}\n",
        "$$\n",
        "\n",
        "To implement this approach, you should use the sentiment\n",
        "lexicon in `sent_lexicon`, which was taken from the\n",
        "following work:\n",
        "\n",
        "> Theresa Wilson, Janyce Wiebe, and Paul Hoffmann\n",
        "(2005). [Recognizing Contextual Polarity in Phrase-Level Sentiment\n",
        "Analysis](http://www.aclweb.org/anthology/H/H05/H05-1044.pdf). HLT-EMNLP."
      ]
    },
    {
      "metadata": {
        "id": "tOFnMvbeeZrc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q: 1.1) Implement this approach and report its classification accuracy. (1 pt)"
      ]
    },
    {
      "metadata": {
        "id": "ED2aTEYutW1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "threshold= 8\n",
        "switch = 'binary'   #takes the value 'weighted' or 'binary'\n",
        "        \n",
        "def classify(S,threshold):\n",
        "  '''classify 1 if S > treshold and 0 otherwise'''\n",
        "  # classifies one review as positive (1) or negative (0)\n",
        "  if S > threshold:\n",
        "    return 1 #positive\n",
        "  else:\n",
        "    return 0 #negative\n",
        "  \n",
        "def calculate_word_score(switch,token_value):\n",
        "  # switch function: calculates the score of each word with either \n",
        "  # the weighted or binary formula\n",
        "  if switch=='weighted':\n",
        "    return token_value[0]*token_value[1]\n",
        "  if switch=='binary':\n",
        "    return token_value[0]\n",
        "\n",
        "def load_lexicon():\n",
        "  # loads lexicon in the memory\n",
        "  lexicon = []\n",
        "  with open(\"sent_lexicon\", mode=\"r+\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "      lexicon.append(line.split(\" \"))\n",
        "  return lexicon\n",
        "\n",
        "# creates a dictionary of sentiment of the words\n",
        "def gimme_word_sentiment(lexicon):\n",
        "  # Returns a dictionary in the format:\n",
        "  #    word: [sentiment, magnitude]\n",
        "  #    sentiment can take 1 or -1\n",
        "  #    magnitude can take 1 or 2\n",
        "  word_dict  = {}     # dictionary of the format \"word\": [sentiment, magnitude]\n",
        "  weight_strong = 2   \n",
        "  weight_weak = 1\n",
        "  negative_sentiment = -1\n",
        "  positive_sentiment = 1\n",
        "  both_neutral = 0\n",
        "  for i in range(len(lexicon)):\n",
        "    token = lexicon[i][2][len(\"word1=\"):]\n",
        "    polarity_text = lexicon[i][5]\n",
        "    if (polarity_text.find(\"negative\") != -1):\n",
        "      word_dict[token]= [negative_sentiment]\n",
        "    elif (polarity_text.find(\"positive\") != -1):\n",
        "      word_dict[token]= [positive_sentiment]\n",
        "    else: \n",
        "      word_dict[token] = [both_neutral]\n",
        "    magnitude_text = lexicon[i][0]\n",
        "    if (magnitude_text.find(\"strongsubj\") != -1):\n",
        "      word_dict[token].append(weight_strong)\n",
        "    else:\n",
        "      word_dict[token].append(weight_weak)\n",
        "    #print(token, \": \", word_dict[token], \"lexicon: \", lexicon[i])\n",
        "  return word_dict\n",
        "\n",
        "def review_score_calculator(reviews, word_dict, switch):\n",
        "  S = np.zeros(len(reviews))\n",
        "  c=0\n",
        "  for review in reviews:\n",
        "    count_token = 0\n",
        "    for sentence in review[\"content\"]:\n",
        "      for token, pos_tag in sentence:\n",
        "        token = token.lower()\n",
        "        token_value = word_dict.get(token)\n",
        "        if token_value is not None:\n",
        "          S[c] = S[c] + calculate_word_score(switch, token_value)\n",
        "    c += 1\n",
        "  return S\n",
        "\n",
        "lexicon = load_lexicon()\n",
        "word_dict = gimme_word_sentiment(lexicon)\n",
        "\n",
        "# loads the reviews in the memory\n",
        "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as h:\n",
        "  reviews = json.load(h)\n",
        "\n",
        "S_binary = review_score_calculator(reviews,word_dict,switch)\n",
        "\n",
        "#classifying the reviews\n",
        "classified_reviews=np.zeros(len(reviews))\n",
        "for i in range(len(reviews)):\n",
        "  classified_reviews[i]=classify(S_binary[i],threshold)\n",
        "             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iy528EUTphz5",
        "colab_type": "code",
        "outputId": "ef69c2a7-647c-4481-8b63-a0af0d34c0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "\n",
        "def evaluate_model(reviews, classified_reviews):\n",
        "  token_results = [] # 1 -> correctly evaluated, 0 -> falsely evaluated\n",
        "  review_sentiment = []\n",
        "  for i in range(len(reviews)):\n",
        "    review_sentiment.append(reviews[i][\"sentiment\"])\n",
        "    if (reviews[i][\"sentiment\"] == \"NEG\" and classified_reviews[i] == 0):\n",
        "      token_results.append(1)\n",
        "    elif (reviews[i][\"sentiment\"] == \"POS\" and classified_reviews[i] == 1):\n",
        "      token_results.append(1)\n",
        "    else:\n",
        "      token_results.append(0)\n",
        "  return token_results , review_sentiment\n",
        "\n",
        "token_results, review_sentiment = evaluate_model(reviews, classified_reviews)\n",
        "    \n",
        "if debug == True:\n",
        "  print(S_binary)\n",
        "  print(token_results)\n",
        "  print(review_sentiment)\n",
        "\n",
        "token_accuracy = sum(token_results)/len(reviews)\n",
        "print(\"Accuracy: %0.2f\" % token_accuracy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Twox0s_3eS0V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "threshold= 8threshold= 8If the sentiment lexicon also has information about the **magnitude** of\n",
        "sentiment (e.g., *“excellent\"* would have higher magnitude than\n",
        "*“good\"*), we could take a more fine-grained approach by adding up all\n",
        "sentiment scores, and deciding the polarity of the movie review using\n",
        "the sign of the weighted score $S_{weighted}$.\n",
        "\n",
        "$$S_{weighted}(w_1w_2...w_n) = \\sum_{i = 1}^{n}SLex\\big[w_i\\big]$$\n",
        "\n",
        "\n",
        "Their lexicon also records two possible magnitudes of sentiment (*weak*\n",
        "and *strong*), so you can implement both the binary and the weighted\n",
        "solutions (please use a switch in your program). For the weighted\n",
        "solution, you can choose the weights intuitively *once* before running\n",
        "the experiment.\n",
        "\n",
        "#### (Q: 1.2) Now incorporate magnitude information and report the classification accuracy. Don't forget to use the threshold. (1 pt)"
      ]
    },
    {
      "metadata": {
        "id": "A4ND3wnxzKWA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Design choice:** Strong words have a weight of 2, and weak words have a weight of 1. This weight is multiplied by -1 if the word has a negative sentiment. As instructed by the TA."
      ]
    },
    {
      "metadata": {
        "id": "qG3hUDnPtkhS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "switch = 'weighted' #takes the value 'weighted' or 'binary'\n",
        "\n",
        "word_dict = gimme_word_sentiment(lexicon)\n",
        "  \n",
        "S_weighted = review_score_calculator(reviews, word_dict, switch)   \n",
        "  \n",
        "#classifying the reviews\n",
        "classified_reviews=np.zeros(len(reviews))\n",
        "for i in range(len(reviews)):\n",
        "  classified_reviews[i] = classify(S_weighted[i], threshold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vVk7CvDpyka",
        "colab_type": "code",
        "outputId": "ddeddf67-5af7-44de-d418-fcb96e897b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "debug = False #for debuging purposes!\n",
        "\n",
        "def evaluate_model(reviews, classified_reviews):\n",
        "  magnitude_results = [] # 1 -> correctly evaluated, 0 -> falsely evaluated\n",
        "  review_sentiment = []\n",
        "  for i in range(len(reviews)):\n",
        "    review_sentiment.append(reviews[i][\"sentiment\"])\n",
        "    if (reviews[i][\"sentiment\"] == \"NEG\" and classified_reviews[i] == 0):\n",
        "      magnitude_results.append(1)\n",
        "    elif (reviews[i][\"sentiment\"] == \"POS\" and classified_reviews[i] == 1):\n",
        "      magnitude_results.append(1)\n",
        "    else:\n",
        "      magnitude_results.append(0)\n",
        "    \n",
        "  return magnitude_results, review_sentiment\n",
        "\n",
        "magnitude_results, review_sentiment = evaluate_model(reviews, \n",
        "                                                     classified_reviews)\n",
        "    \n",
        "if debug == True:\n",
        "  print(S_weighted)\n",
        "  count = 0\n",
        "  for i in range(len(magnitude_results)):\n",
        "    if (magnitude_results[i] != token_results[i]):\n",
        "      count += 1\n",
        "  print(count)\n",
        "  print(magnitude_results)\n",
        "  print(token_results)\n",
        "  print(review_sentiment)\n",
        "  \n",
        "magnitude_accuracy = sum(magnitude_results)/len(reviews) # ..\n",
        "print(\"Accuracy: %0.2f\" % magnitude_accuracy)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9ENYdHs9LDL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "َIt can be seen that adding weights has only improved the results by a very small amount. It should be mentioned that tuning the weights and choosing the optimal combination may result in a higher accuracy.  "
      ]
    },
    {
      "metadata": {
        "id": "iYuDEWy1KwYU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Just for fun:\n",
        "\n",
        "Negative words change the meaning of a positive word to negative. And the other way around. However the methods above do not take this simple grammar rule in consideration. For instance: \\\\\n",
        "\"The movie was not great\"  \\\\\n",
        "\"I did not enjoy the performance of Jasmin\" \\\\\n",
        "\"I was not amused by the plot\" \\\\\n",
        "All the above would be classified as positive reviews by both previous methods, but they are clearly negative reviews. Our hypotesis is: \\\\\n",
        "Can we have a better classifier if we multiply the sentiment of a word by -1 when it is preceeded of a negative word?\\\\\n",
        "Negative words: (the list was taken from this not-academic website: https://www.grammarly.com/blog/negatives/)\n",
        "\n",
        "*   No\n",
        "*   Not\n",
        "*   None\n",
        "*   Nobody\n",
        "*   Nothing\n",
        "*   Neither\n",
        "*   Nowhere\n",
        "*   Never\n",
        "*   Hardly\n",
        "*   Scarcely\n",
        "*   Barely\n",
        "*   Doesn’t\n",
        "*   Isn’t\n",
        "*   Wasn’t\n",
        "*   Shouldn’t\n",
        "*   Wouldn’t\n",
        "*   Couldn’t\n",
        "*   Won’t\n",
        "*   Can’t\n",
        "*   Don’t\n",
        "*   Didn't (not included in the original list, but added by us.)\n"
      ]
    },
    {
      "metadata": {
        "id": "B4SWs_cZKvzd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "threshold= 8\n",
        "switch='weighted'   #takes the value 'weighted' or 'binary'\n",
        "        \n",
        "def classify(S,threshold):\n",
        "  # classifies one review as positive (1) or negative (0)\n",
        "  if S > threshold:\n",
        "    return 1 #positive\n",
        "  else:\n",
        "    return 0 #negative\n",
        "  \n",
        "def calculate_word_score(switch,token_value):\n",
        "  # switch function: calculates the score of each word with either \n",
        "  # the weighted or binary formula\n",
        "  if switch=='weighted':\n",
        "    return token_value[0]*token_value[1]\n",
        "  if switch=='binary':\n",
        "    return token_value[0]\n",
        "\n",
        "def load_lexicon():\n",
        "  # loads lexicon in the memory\n",
        "  lexicon = []\n",
        "  with open(\"sent_lexicon\", mode=\"r+\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "      lexicon.append(line.split(\" \"))\n",
        "  return lexicon\n",
        "\n",
        "# creates a dictionary of sentiment of the words\n",
        "def gimme_word_sentiment(lexicon):\n",
        "  # Returns a dictionary in the format:\n",
        "  #    word: [sentiment, magnitude]\n",
        "  #    sentiment can take 1 or -1\n",
        "  #    magnitude can take 1 or 2\n",
        "  word_dict  = {}     # dictionary of the format \"word\": [sentiment, magnitude]\n",
        "  weight_strong = 2   \n",
        "  weight_weak = 1\n",
        "  negative_sentiment = -1\n",
        "  positive_sentiment = 1\n",
        "  both_neutral = 0\n",
        "  for i in range(len(lexicon)):\n",
        "    token = lexicon[i][2][len(\"word1=\"):]\n",
        "    polarity_text = lexicon[i][5]\n",
        "    if (polarity_text.find(\"negative\") != -1):\n",
        "      word_dict[token]= [negative_sentiment]\n",
        "    elif (polarity_text.find(\"positive\") != -1):\n",
        "      word_dict[token]= [positive_sentiment]\n",
        "    else: \n",
        "      word_dict[token] = [both_neutral]\n",
        "    magnitude_text = lexicon[i][0]\n",
        "    if (magnitude_text.find(\"strongsubj\") != -1):\n",
        "      word_dict[token].append(weight_strong)\n",
        "    else:\n",
        "      word_dict[token].append(weight_weak)\n",
        "    #print(token, \": \", word_dict[token], \"lexicon: \", lexicon[i])\n",
        "  return word_dict\n",
        "\n",
        "def check_negative(maybe_negative):\n",
        "  negative_words = [\"No\", \"Not\", \"None\", \"Nobody\", \"Nothing\", \"Neither\", \n",
        "                    \"Nowhere\", \"Never\", \"Hardly\", \"Scarcely\", \"Barely\", \n",
        "                    \"Doesn’t\", \"Isn’t\", \"Wasn’t\", \"Shouldn’t\", \"Wouldn’t\", \n",
        "                    \"Couldn’t\", \"Won’t\", \"Can’t\",\"Don’t\", \"Didn't\"]\n",
        "  negative_words = [negative_words[i].lower() for i in range (len(negative_words))]\n",
        "  if (maybe_negative in negative_words):\n",
        "    return -1\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "def review_score_calculator(reviews, word_dict, switch):\n",
        "  S = np.zeros(len(reviews))\n",
        "  c=0\n",
        "  for review in reviews:\n",
        "    count_token = 0\n",
        "    for sentence in review[\"content\"]:\n",
        "      for i in range(len(sentence)):\n",
        "        token, pos_tag = sentence[i]\n",
        "        token = token.lower()\n",
        "        token_value = word_dict.get(token)\n",
        "        if token_value is not None:\n",
        "          if i > 0:\n",
        "            negation = check_negative(sentence[i-1][0].lower())  \n",
        "          S[c] = S[c] + negation*calculate_word_score(switch, token_value)\n",
        "    c += 1\n",
        "  return S\n",
        "\n",
        "lexicon = load_lexicon()\n",
        "word_dict = gimme_word_sentiment(lexicon)\n",
        "\n",
        "# loads the reviews in the memory\n",
        "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as h:\n",
        "  reviews = json.load(h)\n",
        "\n",
        "S_binary=review_score_calculator(reviews,word_dict,switch)\n",
        "\n",
        "#classifying the reviews\n",
        "classified_reviews_n=np.zeros(len(reviews))\n",
        "for i in range(len(reviews)):\n",
        "  classified_reviews_n[i]=classify(S_binary[i],threshold)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XWkBWZhuQvz0",
        "colab_type": "code",
        "outputId": "815fbfd1-1d6c-4aa6-e6d8-db4afa7a3630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "debug = False\n",
        "\n",
        "def evaluate_model(reviews, classified_reviews):\n",
        "  token_results = [] # 1 -> correctly evaluated, 0 -> falsely evaluated\n",
        "  review_sentiment = []\n",
        "  for i in range(len(reviews)):\n",
        "    review_sentiment.append(reviews[i][\"sentiment\"])\n",
        "    if (reviews[i][\"sentiment\"] == \"NEG\" and classified_reviews_n[i] == 0):\n",
        "      token_results.append(1)\n",
        "    elif (reviews[i][\"sentiment\"] == \"POS\" and classified_reviews_n[i] == 1):\n",
        "      token_results.append(1)\n",
        "    else:\n",
        "      token_results.append(0)\n",
        "  return token_results , review_sentiment\n",
        "\n",
        "token_results, review_sentiment = evaluate_model(reviews, classified_reviews_n)\n",
        "    \n",
        "if debug == True:\n",
        "  print(S_binary)\n",
        "  print(token_results)\n",
        "  print(review_sentiment)\n",
        "\n",
        "token_accuracy = sum(token_results)/len(reviews)\n",
        "print(\"Accuracy: %0.2f\" % token_accuracy)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EwlWLvhRR0ht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To our surprise, taking in consideration the negatives do not impact the quality of the classifier! This approach my not be not enough to capture the influence of negative words in a sentence, however we conclude that our simple proposed method is not sufficient to make any improvements.\n"
      ]
    },
    {
      "metadata": {
        "id": "h9SHoGPfsAHV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Optional: make a barplot of the two results."
      ]
    },
    {
      "metadata": {
        "id": "8LgBcYcXsEk3",
        "colab_type": "code",
        "outputId": "ec0a4885-23f6-44e7-b9fa-99ef6dda5725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "method = ('Binary', 'Weighted')\n",
        "y_pos = np.arange(len(method))\n",
        "performance = [token_accuracy, magnitude_accuracy]\n",
        " \n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, method)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Method')\n",
        "plt.title('Sentiment analysis by Binary and Weighted methods')\n",
        " \n",
        "plt.show()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f52167f3a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6MFrz8Jink0D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Answering questions in statistically significant ways (1pt)\n",
        "-------------------------------------------------------------"
      ]
    },
    {
      "metadata": {
        "id": "kxkxrldT9Ymc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Does using the magnitude improve the results? Oftentimes, answering questions like this about the performance of\n",
        "different signals and/or algorithms by simply looking at the output\n",
        "numbers is not enough. When dealing with natural language or human\n",
        "ratings, it’s safe to assume that there are infinitely many possible\n",
        "instances that could be used for training and testing, of which the ones\n",
        "we actually train and test on are a tiny sample. Thus, it is possible\n",
        "that observed differences in the reported performance are really just\n",
        "noise. \n",
        "\n",
        "There exist statistical methods which can be used to check for\n",
        "consistency (*statistical significance*) in the results, and one of the\n",
        "simplest such tests is the **sign test**. \n",
        "\n",
        "The sign test is based on the binomial distribution. Count all cases when System 1 is better than System 2, when System 2 is better than System 1, and when they are the same. Call these numbers $Plus$, $Minus$ and $Null$ respectively. \n",
        "\n",
        "The sign test returns the probability that the null hypothesis is true. \n",
        "\n",
        "This probability is called the $p$-value and it can be calculated for the two-sided sign test using the following formula (we multiply by two because this is a two-sided sign test and tests for the significance of differences in either direction):\n",
        "\n",
        "$$2 \\, \\sum\\limits_{i=0}^{k} \\binom{N}{i} \\, q^i \\, (1-q)^{N-i}$$\n",
        "\n",
        "where $$N = 2 \\Big\\lceil \\frac{Null}{2}\\Big\\rceil + Plus + Minus$$ is the total\n",
        "number of cases, and\n",
        "$$k = \\Big\\lceil \\frac{Null}{2}\\Big\\rceil + \\min\\{Plus,Minus\\}$$ is the number of\n",
        "cases with the less common sign. \n",
        "\n",
        "In this experiment, $q = 0.5$. Here, we\n",
        "treat ties by adding half a point to either side, rounding up to the\n",
        "nearest integer if necessary. \n",
        "\n",
        "\n",
        "#### (Q 2.1): Implement the sign test. Is the difference between the two symbolic systems significant? What is the p-value? (1 pt)\n",
        "\n",
        "You should use the `comb` function from `scipy` and the `decimal` package for the stable adding of numbers in the final summation.\n",
        "\n",
        "You can quickly verify the correctness of\n",
        "your sign test code using a [free online\n",
        "tool](https://www.graphpad.com/quickcalcs/binomial1.cfm)."
      ]
    },
    {
      "metadata": {
        "id": "de5l4oPkE-BS",
        "colab_type": "code",
        "outputId": "b9e83f3a-20a0-42fb-acf0-b9dad085752d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from decimal import *\n",
        "import scipy\n",
        "\n",
        "\n",
        "\n",
        "def sign_test(results_1, results_2):\n",
        "  \"\"\"test for significance\n",
        "  results_1 is a list of classification results (+ for correct, - incorrect)\n",
        "  results_2 is a list of classification results (+ for correct, - incorrect)\n",
        "  \"\"\"\n",
        "  ties, plus, minus = 0, 0, 0\n",
        "  q=0.5\n",
        "  \n",
        "  # \"-\" carries the error\n",
        "  for i in range(0, len(results_1)):\n",
        "    if results_1[i] == results_2[i]:\n",
        "      ties += 1\n",
        "    elif results_1[i] == 0: \n",
        "      plus += 1\n",
        "    elif results_2[i] == 0: \n",
        "      minus += 1\n",
        "\n",
        "  n = 2*math.ceil(ties/2)+plus+minus\n",
        "  k = math.ceil(ties/2)+min(plus,minus)\n",
        "\n",
        "  summation = Decimal(0.0)\n",
        "  for i in range(0,int(k)+1):\n",
        "      summation += Decimal(scipy.special.comb(n,i,exact=True))\n",
        "  \n",
        "  # use two-tailed version of test\n",
        "  summation *= 2\n",
        "  summation *= (Decimal(q)**Decimal(n))\n",
        "  \n",
        "  print(\"the difference is\", \n",
        "        \"not significant\" if summation >= 0.05 else \"significant\")\n",
        "  \n",
        "  return summation\n",
        "\n",
        "p_value = sign_test(token_results, magnitude_results)\n",
        "print(\"p_value =\", p_value)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the difference is not significant\n",
            "p_value = 0.8756244234337031344389177957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhU_tk-BOaXb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using the Sign test\n",
        "\n",
        "**From now on, report all differences between systems using the\n",
        "sign test.** You can think about a change that you apply to one system, as a\n",
        " new system.\n",
        "    \n",
        "You should report statistical test\n",
        "results in an appropriate form – if there are several different methods\n",
        "(i.e., systems) to compare, tests can only be applied to pairs of them\n",
        "at a time. This creates a triangular matrix of test results in the\n",
        "general case. When reporting these pair-wise differences, you should\n",
        "summarise trends to avoid redundancy.\n"
      ]
    },
    {
      "metadata": {
        "id": "LibV4nR89BXb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Naive Bayes (8pt + 1pt bonus)\n",
        "=========="
      ]
    },
    {
      "metadata": {
        "id": "fnF9adQnuwia",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Your second task is to program a simple Machine Learning approach that operates\n",
        "on a simple Bag-of-Words (BoW) representation of the text data, as\n",
        "described in Pang et al. (2002). In this approach, the only features we\n",
        "will consider are the words in the text themselves, without bringing in\n",
        "external sources of information. The BoW model is a popular way of\n",
        "representing text information as vectors (or points in space), making it\n",
        "easy to apply classical Machine Learning algorithms on NLP tasks.\n",
        "However, the BoW representation is also very crude, since it discards\n",
        "all information related to word order and grammatical structure in the\n",
        "original text.\n",
        "\n",
        "## Writing your own classifier\n",
        "\n",
        "Write your own code to implement the Naive Bayes (NB) classifier. As\n",
        "a reminder, the Naive Bayes classifier works according to the following\n",
        "equation:\n",
        "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} P(c|\\bar{f}) = \\operatorname*{arg\\,max}_{c \\in C} P(c)\\prod^n_{i=1} P(f_i|c)$$\n",
        "where $C = \\{ \\text{POS}, \\text{NEG} \\}$ is the set of possible classes,\n",
        "$\\hat{c} \\in C$ is the most probable class, and $\\bar{f}$ is the feature\n",
        "vector. Remember that we use the log of these probabilities when making\n",
        "a prediction:\n",
        "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} \\Big\\{\\log P(c) + \\sum^n_{i=1} \\log P(f_i|c)\\Big\\}$$\n",
        "\n",
        "You can find more details about Naive Bayes in [Jurafsky &\n",
        "Martin](https://web.stanford.edu/~jurafsky/slp3/). You can also look at\n",
        "this helpful\n",
        "[pseudo-code](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html).\n",
        "\n",
        "*Note: this section and the next aim to put you a position to replicate\n",
        "    Pang et al., Naive Bayes results. However, the numerical results\n",
        "    will differ from theirs, as they used different data.*\n",
        "\n",
        "**You must write the Naive Bayes training and prediction code from\n",
        "scratch.** You will not be given credit for using off-the-shelf Machine\n",
        "Learning libraries.\n",
        "\n",
        "The data contains the text of the reviews, where each document consists\n",
        "of the sentences in the review, the sentiment of the review and an index\n",
        "(cv) that you will later use for cross-validation. You will find the\n",
        "text has already been tokenised and POS-tagged for you. Your algorithm\n",
        "should read in the text, **lowercase it**, and store the words and their\n",
        "frequencies in an appropriate data structure that allows for easy\n",
        "computation of the probabilities used in the Naive Bayes algorithm, and\n",
        "then make predictions for new instances."
      ]
    },
    {
      "metadata": {
        "id": "gsZRhaI3WvzC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q3.1) Train your classifier on (positive and negative) reviews with cv-value 000-899, and test it on the remaining reviews cv900–cv999.  Report results using simple classification accuracy as your evaluation metric. Your  features are the word vocabulary. The value of a feature is the count of that feature (word) in the document. (2pts)\n"
      ]
    },
    {
      "metadata": {
        "id": "KQBAygDx_tad",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DESIGN CHOICE**: There are some words that occur in texts related to one class and not the other. These words are added to the vocabulary and will hava a count of zero for the class they don't appear in. As a result, they will have a zero probability which would lead to a $-\\infty$ log probability. in order to remedy this, we replace each zero probability with a number greater than one. Here we are using $e$. Since the other probabilities will be less than one, and therefore have a negative $log$, the only positive log probabilities will be the ones that had a zero count. This makes them easy to detect. Later, in the testing phase, the log probabilities are only added in the calculation if they are negative."
      ]
    },
    {
      "metadata": {
        "id": "G7zaJYGFvIJ3",
        "colab_type": "code",
        "outputId": "5c3ae5dc-1ee7-4572-d942-4c2d80a79c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Implementation of Naive Bayes Classifier\n",
        "\n",
        "\n",
        "t_size = int(.9*len(reviews)) #training size\n",
        "negative_size = int(t_size/2)\n",
        "train_set_i = [] # stores indexes of the training set\n",
        "for i in range(0, negative_size): # indexes of the negative reviews\n",
        "  train_set_i.append(i)\n",
        "for i in range(int(len(reviews)/2), len(reviews) - 100): # indexes of the positive reviews\n",
        "  train_set_i.append(i)\n",
        "\n",
        "\n",
        "def init_dict(reviews):\n",
        "  w_dict = {} #count the number of times each word appears in each class \n",
        "  for r in range(len(reviews)):\n",
        "    # loops through all reviews and add the words to the dict word_frequency.\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        w_dict[word] = [0, 0]  # [NEGATIVE, POSITIVE]\n",
        "  return w_dict\n",
        "        \n",
        "def count(reviews, index):\n",
        "  ''' counts the presence in the set of pos and neg reviews\n",
        "  returns:\n",
        "    word_frequency: a dictionary, consisting of the number of times EACH word \n",
        "    happened in each class\n",
        "    vocab _frequency: a vector, consisting of the totall times ALL the words \n",
        "    were used in each class\n",
        "  '''\n",
        "  \n",
        "  word_frequency = init_dict(reviews)\n",
        "  review_class = 0\n",
        "  for r in index:\n",
        "    if (reviews[r][\"sentiment\"] == 'NEG'):\n",
        "      review_class = 0\n",
        "    else:\n",
        "      review_class = 1\n",
        "    for sentence in reviews[r][\"content\"]:\n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        word_frequency[word][review_class] += 1\n",
        "\n",
        "  vocab_frequency = [0, 0] # stores the total times all the words used in each class\n",
        "  vocab_frequency = np.sum(list(word_frequency.values()), axis=0)\n",
        "      \n",
        "  return vocab_frequency, word_frequency\n",
        "\n",
        "def log_probabilities(prob_class, word_frequency, prob_word_given_class, w_dic):\n",
        "  # spaceship to the log-space:\n",
        "  ln_p_class = [np.log(prob_class[0]), np.log(prob_class[1])] \n",
        "  ln_p_word_g_class = w_dic\n",
        "  for word in word_frequency:\n",
        "    # work around words that do not happen in one of the classes.\n",
        "    # We avoind taking the log of zero by replacing it by a number higher than 1,\n",
        "    # we use the natural constant e such that ln(e) = 1 > ln (0<x<1) < 0\n",
        "    # This approach requires the classifier to filter out all log probabiliter \n",
        "    # higher than zero.\n",
        "    if (prob_word_given_class[word][0] <= 0):\n",
        "      pwgc_n = np.e\n",
        "    else:\n",
        "      pwgc_n = prob_word_given_class[word][0]\n",
        "    if (prob_word_given_class[word][1] <= 0):\n",
        "      pwgc_p = np.e\n",
        "    else:\n",
        "      # In the case of the word being present in that class, it just takes the \n",
        "      # natural logarithm as it is suposed to do.\n",
        "      pwgc_p = prob_word_given_class[word][1]\n",
        "    ln_p_word_g_class[word] = [np.log(pwgc_n),\n",
        "                               np.log(pwgc_p)]\n",
        "  return ln_p_class, ln_p_word_g_class\n",
        "\n",
        "def class_probability(index, negative_size):\n",
        "  # returns the probability of each class in the training set\n",
        "  prob_class  = [negative_size/len(index), 1-negative_size/len(index)]\n",
        "  return prob_class\n",
        "\n",
        "def word_probability(w_dic, vocab_frequency, word_frequency):\n",
        "  # returns the probability of each word given the class, for each class\n",
        "  prob_word_given_class = w_dic\n",
        "  for word in word_frequency:\n",
        "    for i in range (2):\n",
        "      prob_word_given_class[word][i] = word_frequency[word][i]/vocab_frequency[i]\n",
        "      \n",
        "  return prob_word_given_class\n",
        "\n",
        "def training(index, reviews, negative_size, vocab_frequency, word_frequency):\n",
        "  # trains the NB_classifier\n",
        "  w_dic=init_dict(reviews)\n",
        "  prob_word_given_class = word_probability(w_dic,\n",
        "                                           vocab_frequency, \n",
        "                                           word_frequency)\n",
        "  \n",
        "  prob_class = class_probability(index, negative_size)\n",
        "\n",
        "  ln_p_class, ln_p_word_g_class = log_probabilities(prob_class,\n",
        "                                                    word_frequency,\n",
        "                                                    prob_word_given_class,\n",
        "                                                    w_dic)\n",
        "  return  ln_p_class, ln_p_word_g_class\n",
        "\n",
        "\n",
        "# Train the Naive Bayes Classifier:\n",
        "vocab_frequency, word_frequency = count(reviews,\n",
        "                                        train_set_i)\n",
        "\n",
        "ln_p_class, ln_p_word_g_class = training(train_set_i,\n",
        "                                             reviews,\n",
        "                                             negative_size, \n",
        "                                             vocab_frequency,\n",
        "                                             word_frequency)\n",
        "\n",
        "# Test the NB-Classifier\n",
        "test_set_i = [] # stores indexes of the test set\n",
        "for i in range(int(t_size/2),int(len(reviews)/2)): # indexes of the negative reviews\n",
        "  test_set_i.append(i)\n",
        "for i in range(len(reviews) - 100, len(reviews)): # indexes of the positive reviews\n",
        "  test_set_i.append(i)\n",
        "  \n",
        "def classify(ln_p_class, ln_p_word_g_class, test_set_i, reviews):\n",
        "  # ^c = argmax [ln(prob_class(c) + sum(prob_word_in_class)]\n",
        "  NB_classifier = []\n",
        "  for r in test_set_i:\n",
        "    n_or_p = [ln_p_class[0] , ln_p_class[1]]\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        # checks if word was used in the negative class\n",
        "        if ln_p_word_g_class[word][0] < 0: \n",
        "          n_or_p[0] += ln_p_word_g_class[word][0]\n",
        "        # checks if word was used in the positive class\n",
        "        if ln_p_word_g_class[word][1] < 0: \n",
        "          n_or_p[1] += ln_p_word_g_class[word][1]\n",
        "    if (n_or_p[0] >= n_or_p[1]):\n",
        "      NB_classifier.append([0,r]) # classified as negative \n",
        "    else: \n",
        "      NB_classifier.append([1,r]) # classified as positive\n",
        "  return NB_classifier\n",
        "\n",
        "\n",
        "def evaluate_NB_classifier(NB_classifier, test_set_i, reviews):\n",
        "  NB_results = [] # 1 -> correctly evaluated, 0 -> falsely evaluated\n",
        "  review_sentiment = []\n",
        "  for i in range(len(test_set_i)):\n",
        "  #for i in test_set_i:\n",
        "    r = NB_classifier[i][1] # r stores the index of the review \n",
        "    review_sentiment.append(reviews[r][\"sentiment\"])\n",
        "    if (reviews[r][\"sentiment\"] == \"NEG\" and NB_classifier[i][0] == 0):\n",
        "      NB_results.append(1)\n",
        "    elif (reviews[r][\"sentiment\"] == \"POS\" and NB_classifier[i][0] == 1):\n",
        "      NB_results.append(1)\n",
        "    else:\n",
        "      NB_results.append(0)\n",
        "  return NB_results\n",
        "\n",
        "#Test the Naive Bayes Classifier:\n",
        "NB_classifier = classify(ln_p_class,\n",
        "                         ln_p_word_g_class,\n",
        "                         test_set_i,\n",
        "                         reviews)\n",
        "#print(NB_classifier)\n",
        "results_without_smoothing = evaluate_NB_classifier(NB_classifier, \n",
        "                                                   test_set_i, \n",
        "                                                   reviews)\n",
        "#print(results_without_smoothing)\n",
        "NB_normal = sum(results_without_smoothing)/len(results_without_smoothing)\n",
        "print(\"accuracy: \", sum(results_without_smoothing)/len(results_without_smoothing))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xdup4O5z-s33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As can be seen, Naive Bayse without smoothing is about as bad as a random classifier! Part of it is due to how it handles unseen words - it ignores them. This problem becomes very evident in the following seciton where we deal with a unballanced dataset."
      ]
    },
    {
      "metadata": {
        "id": "0INK-PBoM6CB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Bonus Questions) Would you consider accuracy to also be a good way to evaluate your classifier in a situation where 90% of your data instances are of positive movie reviews? (1pt)\n",
        "\n",
        "You can simulate this scenario by keeping the positive reviews\n",
        "data unchanged, but only using negative reviews cv000–cv089 for\n",
        "training, and cv900–cv909 for testing. Calculate the classification\n",
        "accuracy, and explain what changed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "85d5e1ce-fd6f-40a0-e51d-7df226477039",
        "id": "MngeLAoD_cEP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "negative_size = 90\n",
        "negative_training_start = 0\n",
        "negative_training_end = negative_size\n",
        "prositive_training_start = int(len(reviews)/2)\n",
        "positive_training_end = len(reviews) - 100\n",
        "\n",
        "train_set_i = [] # stores indexes of the training set\n",
        "# indexes of the negative reviews\n",
        "for i in range(negative_training_start , negative_training_end): \n",
        "  train_set_i.append(i)\n",
        "# indexes of the positive reviews\n",
        "for i in range(prositive_training_start, positive_training_end): \n",
        "  train_set_i.append(i)\n",
        "\n",
        "negative_test_start = negative_training_end\n",
        "negative_test_end = int(negative_training_end +.1*negative_size)\n",
        "positive_test_start = positive_training_end\n",
        "positive_test_end = len(reviews)\n",
        "\n",
        "test_set_i = [] # stores indexes of the training set\n",
        "# indexes of the negative reviews\n",
        "for i in range(negative_test_start, negative_test_end): \n",
        "  test_set_i.append(i)\n",
        "  \n",
        "# indexes of the positive reviews\n",
        "for i in range(positive_test_start, positive_test_end): \n",
        "  test_set_i.append(i)\n",
        "  \n",
        "# Train the Naive Bayes Classifier:  \n",
        "vocab_frequency, word_frequency = count(reviews,\n",
        "                                        train_set_i)\n",
        "\n",
        "ln_p_class, ln_p_word_g_class = training(train_set_i,\n",
        "                                             reviews,\n",
        "                                             negative_size, \n",
        "                                             vocab_frequency,\n",
        "                                             word_frequency)\n",
        "\n",
        "print(\" Positive bias:\", np.exp(ln_p_class[1]), \n",
        "      \"\\n Negative bias:\", np.exp(ln_p_class[0]))\n",
        "\n",
        "# Test the Naive Bayes Classifier:\n",
        "NB_classifier = classify(ln_p_class,\n",
        "                         ln_p_word_g_class,\n",
        "                         test_set_i,\n",
        "                         reviews)\n",
        "\n",
        "results_uneven = evaluate_NB_classifier(NB_classifier, \n",
        "                                        test_set_i, \n",
        "                                        reviews)\n",
        "print(\"acuracy: \", sum(results_uneven)/len(results_uneven))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Positive bias: 0.9090909090909091 \n",
            " Negative bias: 0.0909090909090909\n",
            "acuracy:  0.08256880733944955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FRrfacAnKTvV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(Bonus Question)** Discussion of the results: \\\\\n",
        "The Naive Bayes classifier does about as good as randomly classifying reviews as *positive* or *negative*. Which means that this approach is about as bad as tossing a coin. The classification is done by:\n",
        "\n",
        "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} \\Big\\{\\log P(c) + \\sum^n_{i=1} \\log P(f_i|c)\\Big\\}$$\n",
        "\n",
        "For Q3.1 the reviews are balanced, which means that $P(c = negative ) = P(c = positive) = 0.5 $ . The classification is done purelly on the words in each review. However, most words are nouns, conectives and verbs without a particular conotation indepented of cotext. A large part of this sum $\\sum^n_{i=1} \\log P(f_i|c) $ consists of words that are not relevant for the sentiment classification. \\\\\n",
        "\n",
        "For the Bonus Question, 90% of our training data and 90% of our test data consists of positive reviews. A classifier that classifies all test data as positive would perform 90% accurate already! For the Naive Bayes Classifier $P(c = positive ) = 9P(c = negative) = 0.9 $, we would expect the classifier has a quite large bias towards positive reviews. Yet, its performance is lower than 9%. \\\\\n",
        "\n",
        "That is due to how to the sum part of the formula: $\\sum^n_{i=1} \\log P(f_i|c) $ and to a detail of the implementation. We are suming the logs of numbers between zero and 1. We are then summing negative numbers. However when a word wasn't seen in a class, it just ignores it. Which means that we are summing $0 > log(0<x<1)$. As the classifier was trained with much more positive words than negative words, during the classification it has to ignore a lot of unseen negative words. From our results, this happens in such a scale that is enough to overcome the large positive bias.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "6wJzcHX3WUDm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Smoothing\n",
        "\n",
        "The presence of words in the test dataset that\n",
        "haven’t been seen during training can cause probabilities in the Naive\n",
        "Bayes classifier to be $0$, thus making that particular test instance\n",
        "undecidable. The standard way to mitigate this effect (as well as to\n",
        "give more clout to rare words) is to use smoothing, in which the\n",
        "probability fraction\n",
        "$$\\frac{\\text{count}(w_i, c)}{\\sum\\limits_{w\\in V} \\text{count}(w, c)}$$ for a word\n",
        "$w_i$ becomes\n",
        "$$\\frac{\\text{count}(w_i, c) + \\text{smoothing}(w_i)}{\\sum\\limits_{w\\in V} \\text{count}(w, c) + \\sum\\limits_{w \\in V} \\text{smoothing}(w)}$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PBNIcbwUWphC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q3.2) Implement Laplace feature smoothing (1pt)\n",
        "($smoothing(\\cdot) = \\kappa$, constant for all words) in your Naive\n",
        "Bayes classifier’s code, and report the impact on performance. \n",
        "Use $\\kappa = 1$."
      ]
    },
    {
      "metadata": {
        "id": "g03yflCc9kpW",
        "colab_type": "code",
        "outputId": "77815d66-779c-4a10-a141-3c36772b2d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "kappa=1\n",
        "\n",
        "def smoothing(vocab_frequency,word_frequency):\n",
        "  for word in word_frequency:\n",
        "    for i in range(len(word_frequency[word])):\n",
        "      word_frequency[word][i] += kappa\n",
        "\n",
        "  for i in range(len(vocab_frequency)):\n",
        "    vocab_frequency[i] += len(word_frequency)*kappa\n",
        "  return vocab_frequency,word_frequency \n",
        "\n",
        "#making the train indices\n",
        "t_size = int(.9*len(reviews)) #training size\n",
        "negative_size = int(t_size/2)\n",
        "train_set_i = [] # stores indexes of the training set\n",
        "for i in range(0, negative_size): # indexes of the negative reviews\n",
        "  train_set_i.append(i)\n",
        "for i in range(int(len(reviews)/2), len(reviews) - 100): # indexes of the positive reviews\n",
        "  train_set_i.append(i)\n",
        "  \n",
        "#making the test indices\n",
        "test_set_i = [] # stores indexes of the test set\n",
        "for i in range(int(t_size/2),int(len(reviews)/2)): # indexes of the negative reviews\n",
        "  test_set_i.append(i)\n",
        "for i in range(len(reviews) - 100, len(reviews)): # indexes of the positive reviews\n",
        "  test_set_i.append(i)\n",
        "\n",
        "#adding smoothing\n",
        "vocab_frequency, word_frequency = count(reviews,\n",
        "                                        train_set_i)\n",
        "\n",
        "vocab_frequency,word_frequency= smoothing(vocab_frequency,word_frequency)\n",
        "\n",
        "#training with the smoothed frequencies\n",
        "ln_p_class, ln_p_word_g_class = training(train_set_i, \n",
        "                                         reviews,\n",
        "                                         negative_size, \n",
        "                                         vocab_frequency, \n",
        "                                         word_frequency)\n",
        "\n",
        "#classifying \n",
        "NB_classifier = classify(ln_p_class,\n",
        "                         ln_p_word_g_class,\n",
        "                         test_set_i,\n",
        "                         reviews)\n",
        "\n",
        "#evaluating\n",
        "results_with_smoothing = evaluate_NB_classifier(NB_classifier, \n",
        "                                                   test_set_i, \n",
        "                                                   reviews)\n",
        "print(\"acuracy: \", sum(results_with_smoothing)/len(results_with_smoothing))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acuracy:  0.825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gZ3k4QgxJwyL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see a very large step improvement by just using a simple smoothing technique. This shows once again how much the unseen words were affecting the results of our classifier before. Smoothing is successful in remedying this situation."
      ]
    },
    {
      "metadata": {
        "id": "-conSBddWWyN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q3.3) Is the difference between non smoothed (Q3.1) and smoothed (Q3.2) statistically significant? (0.5pt)"
      ]
    },
    {
      "metadata": {
        "id": "CCvSNGlHMUPz",
        "colab_type": "code",
        "outputId": "eb54a9df-4e4e-4c13-cb0b-64435f081561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "p_value = sign_test(results_without_smoothing, results_with_smoothing)\n",
        "print(\"p_value =\", p_value)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the difference is significant\n",
            "p_value = 0.000003547178174130642586494974890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZiGcgwba87D5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cross-validation\n",
        "\n",
        "A serious danger in using Machine Learning on small datasets, with many\n",
        "iterations of slightly different versions of the algorithms, is that we\n",
        "end up with Type III errors, also called the “testing hypotheses\n",
        "suggested by the data” errors. This type of error occurs when we make\n",
        "repeated improvements to our classifiers by playing with features and\n",
        "their processing, but we don’t get a fresh, never-before seen test\n",
        "dataset every time. Thus, we risk developing a classifier that’s better\n",
        "and better on our data, but worse and worse at generalizing to new,\n",
        "never-before seen data.\n",
        "\n",
        "A simple method to guard against Type III errors is to use\n",
        "cross-validation. In N-fold cross-validation, we divide the data into N\n",
        "distinct chunks / folds. Then, we repeat the experiment N times, each\n",
        "time holding out one of the chunks for testing, training our classifier\n",
        "on the remaining N - 1 data chunks, and reporting performance on the\n",
        "held-out chunk. We can use different strategies for dividing the data:\n",
        "\n",
        "-   Consecutive splitting:\n",
        "  - cv000–cv099 = Split 1\n",
        "  - cv100–cv199 = Split 2\n",
        "  - etc.\n",
        "  \n",
        "-   Round-robin splitting (mod 10):\n",
        "  - cv000, cv010, cv020, … = Split 1\n",
        "  - cv001, cv011, cv021, … = Split 2\n",
        "  - etc.\n",
        "\n",
        "-   Random sampling/splitting\n",
        "  - Not used here (but you may choose to split this way in a non-educational situation)\n",
        "\n",
        "#### (Q3.4) Write the code to implement 10-fold cross-validation using round-robin splitting for your Naive Bayes classifier from Q3.2 and compute the 10 accuracies. Report the final performance, which is the average of the performances per fold. If all splits perform equally well, this is a good sign. (1pt)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3KeCGPa7Nuzx",
        "colab_type": "code",
        "outputId": "b005caf4-86b2-4879-ed35-45c21dac50f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def round_robin_split(reviews, mod = 10): \n",
        "  ''' return a matrix with wich line the indexes of the reviews for this split.\n",
        "  '''\n",
        "  splits = []\n",
        "  for s in range(mod):\n",
        "    splits.append([])\n",
        "    for i in range(s, len(reviews), mod):\n",
        "      splits[s].append(i)\n",
        "  return splits\n",
        "\n",
        "def nr_negative (reviews, splits): \n",
        "  ''' return a vector with the number of negative reviews per split.\n",
        "    by using round_robin_split 10 we get 100 negative reviews per split.\n",
        "  '''\n",
        "  negative_size = []\n",
        "  for split in range(len(splits)): \n",
        "    negative_size.append([])\n",
        "    negative_size[split] = 0\n",
        "    for review_i in splits[split]:\n",
        "      if reviews[review_i]['sentiment'] == 'NEG': \n",
        "        negative_size[split] += 1\n",
        "  return negative_size\n",
        "\n",
        "\n",
        "\n",
        "def train_test_sets(splits, m, negative_sizes): \n",
        "  ''' creates the test set and the training set.\n",
        "  returns:\n",
        "    train_set_i    indexes of the training set\n",
        "    test_set_i     indexes of the test set\n",
        "    negative_size  number of negative revies in the training set\n",
        "  '''\n",
        "  train_set_i = []\n",
        "  negative_size = 0\n",
        "  for i in range(mod):\n",
        "    if i == m :\n",
        "      test_set_i = splits[i]\n",
        "    else:\n",
        "      train_set_i += splits[i]\n",
        "      negative_size +=  negative_sizes[i]\n",
        "  return train_set_i, test_set_i, negative_size\n",
        "\n",
        "mod = 10\n",
        "splits = round_robin_split(reviews, mod = 10)\n",
        "negative_sizes = nr_negative (reviews, splits)\n",
        "\n",
        "# Train the Naive Bayes Classifier:  \n",
        "results_split = []\n",
        "for m in range(mod): \n",
        "  \n",
        "  \n",
        "  train_set_i, test_set_i, negative_size = train_test_sets(splits, \n",
        "                                                           m, \n",
        "                                                           negative_sizes)\n",
        "  # Train the Naive Bayes Classifier:\n",
        "  vocab_frequency, word_frequency = count(reviews,\n",
        "                                          train_set_i) \n",
        "    \n",
        "  smooth_switch = True\n",
        "  if smooth_switch:\n",
        "    vocab_frequency, word_frequency = smoothing(vocab_frequency,\n",
        "                                                word_frequency)\n",
        "\n",
        "  ln_p_class, ln_p_word_g_class = training(train_set_i,\n",
        "                                           reviews,\n",
        "                                           negative_size, \n",
        "                                           vocab_frequency,\n",
        "                                           word_frequency)\n",
        "  # Test the Naive Bayes Classifier:\n",
        "  NB_classifier = classify(ln_p_class,\n",
        "                           ln_p_word_g_class,\n",
        "                           test_set_i,\n",
        "                           reviews)\n",
        "\n",
        "  results_split.append(evaluate_NB_classifier(NB_classifier, \n",
        "                                          test_set_i, \n",
        "                                          reviews))\n",
        "  print(m,\") acuracy: \", sum(results_split[m])/len(results_split[m]))\n",
        "\n",
        "  \n",
        "def report_fold_performance(results_split, print_performance = False):\n",
        "  fold_performance = [sum(results_split[m])/len(results_split[m]) for m in range(len(results_split))]\n",
        "\n",
        "  mean_performance = np.mean(fold_performance)\n",
        "  var_performance = np.var(fold_performance)\n",
        "\n",
        "  if print_performance:\n",
        "    print(\"Mean performance: \", mean_performance, \n",
        "          \"\\n Variance:\", var_performance)\n",
        "    \n",
        "  return mean_performance, var_performance\n",
        "_ = report_fold_performance(results_split, print_performance = True)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 ) acuracy:  0.79\n",
            "1 ) acuracy:  0.835\n",
            "2 ) acuracy:  0.81\n",
            "3 ) acuracy:  0.83\n",
            "4 ) acuracy:  0.775\n",
            "5 ) acuracy:  0.845\n",
            "6 ) acuracy:  0.83\n",
            "7 ) acuracy:  0.785\n",
            "8 ) acuracy:  0.825\n",
            "9 ) acuracy:  0.845\n",
            "Mean performance:  0.817 \n",
            " Variance: 0.0005859999999999986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "otdlsDXBNyOa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q3.5) Write code to calculate and report variance, in addition to the final performance. (1pt)\n",
        "\n",
        "**Please report all future results using 10-fold cross-validation now\n",
        "(unless told to use the held-out test set).**"
      ]
    },
    {
      "metadata": {
        "id": "ZoBQm1KuNzNR",
        "colab_type": "code",
        "outputId": "7663932a-2a09-4b6d-a9b0-6bb30cb3dafb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "smoothed_NB = report_fold_performance(results_split, print_performance = True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean performance:  0.817 \n",
            " Variance: 0.0005859999999999986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s6A2zX9_BRKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Features, overfitting, and the curse of dimensionality\n",
        "\n",
        "In the Bag-of-Words model, ideally we would like each distinct word in\n",
        "the text to be mapped to its own dimension in the output vector\n",
        "representation. However, real world text is messy, and we need to decide\n",
        "on what we consider to be a word. For example, is “`word`\" different\n",
        "from “`Word`\", from “`word`”, or from “`words`\"? Too strict a\n",
        "definition, and the number of features explodes, while our algorithm\n",
        "fails to learn anything generalisable. Too lax, and we risk destroying\n",
        "our learning signal. In the following section, you will learn about\n",
        "confronting the feature sparsity and the overfitting problems as they\n",
        "occur in NLP classification tasks."
      ]
    },
    {
      "metadata": {
        "id": "EKK8FNt8VtcZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q3.6): A touch of linguistics (1pt)\n",
        "\n",
        "Taking a step further, you can use stemming to\n",
        "hash different inflections of a word to the same feature in the BoW\n",
        "vector space. How does the performance of your classifier change when\n",
        "you use stemming on your training and test datasets? Please use the [Porter stemming\n",
        "    algorithm](http://www.nltk.org/howto/stem.html) from NLTK.\n",
        " Also, you should do cross validation and concatenate the predictions from all folds to compute the significance."
      ]
    },
    {
      "metadata": {
        "id": "NxtCul1IrBi_",
        "colab_type": "code",
        "outputId": "3a28242b-11d2-4e72-a961-f1d234ec8d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "  \n",
        "def stem_reviews(stemmed_reviews):\n",
        "  for r in  range(len(stemmed_reviews)):\n",
        "    stemmed_sentences = []\n",
        "    for sentence in stemmed_reviews[r][\"content\"]:\n",
        "      stemmed_sentence = []\n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        word = stemmer.stem(word)\n",
        "        stemmed_sentence.append([word, pos_tag])\n",
        "      stemmed_sentences.append(stemmed_sentence)\n",
        "    stemmed_reviews[r][\"content\"] = stemmed_sentences\n",
        "  return stemmed_reviews\n",
        "\n",
        "def init_dict_with_stemming(reviews):\n",
        "  w_dict = {} \n",
        "  for r in range(len(reviews)):\n",
        "    # loops through all reviews and add the words to w_dict.\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        word = stemmer.stem(word)\n",
        "        w_dict[str(word)] = [0, 0]  # [NEGATIVE, POSITIVE]\n",
        "  return w_dict\n",
        "\n",
        "\n",
        "#cross-validation\n",
        "mod=10\n",
        "results_with_stemming = []\n",
        "splits = round_robin_split(reviews, mod = 10)\n",
        "negative_sizes = nr_negative (reviews, splits)\n",
        "\n",
        "debug = True\n",
        "  \n",
        "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  stemmed_reviews = json.load(f)\n",
        "\n",
        "# Just stem the complete review once and use the standard functions created before!\n",
        "if debug:\n",
        "    print(\"stemming reviews in progress ...\")\n",
        "stemmed_reviews = stem_reviews(stemmed_reviews) \n",
        "\n",
        "\n",
        "for m in range(mod): \n",
        "  train_set_i, test_set_i, negative_size = train_test_sets(splits, \n",
        "                                                         m, \n",
        "                                                         negative_sizes)\n",
        "  # Train the Naive Bayes Classifier:\n",
        "  vocab_frequency, word_frequency = count(stemmed_reviews,\n",
        "                                          train_set_i) \n",
        "\n",
        "  smooth_switch = True\n",
        "  if smooth_switch:\n",
        "    vocab_frequency, word_frequency = smoothing(vocab_frequency,\n",
        "                                                word_frequency)\n",
        "\n",
        "  ln_p_class, ln_p_word_g_class = training(train_set_i,\n",
        "                                           stemmed_reviews,\n",
        "                                           negative_size, \n",
        "                                           vocab_frequency,\n",
        "                                           word_frequency)\n",
        "  # Test the Naive Bayes Classifier:\n",
        "  NB_classifier = classify(ln_p_class,\n",
        "                           ln_p_word_g_class,\n",
        "                           test_set_i,\n",
        "                           stemmed_reviews)\n",
        "\n",
        "  results_with_stemming.append(evaluate_NB_classifier(NB_classifier, \n",
        "                                                      test_set_i, \n",
        "                                                      stemmed_reviews))\n",
        "\n",
        "  print(m,\") acuracy: \", \n",
        "        sum(results_with_stemming[m])/len(results_with_stemming[m]))\n",
        "  \n",
        "\n",
        "stem_NB = report_fold_performance(results_with_stemming, print_performance = True)\n",
        "                                                   \n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stemming reviews in progress ...\n",
            "0 ) acuracy:  0.78\n",
            "1 ) acuracy:  0.84\n",
            "2 ) acuracy:  0.81\n",
            "3 ) acuracy:  0.85\n",
            "4 ) acuracy:  0.775\n",
            "5 ) acuracy:  0.835\n",
            "6 ) acuracy:  0.815\n",
            "7 ) acuracy:  0.775\n",
            "8 ) acuracy:  0.83\n",
            "9 ) acuracy:  0.84\n",
            "Mean performance:  0.8150000000000001 \n",
            " Variance: 0.0007549999999999986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6SrJ1BeLXTnk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q3.7): Is the difference between NB with smoothing and NB with smoothing+stemming significant? (0.5pt)\n"
      ]
    },
    {
      "metadata": {
        "id": "gYqKBOiIrInT",
        "colab_type": "code",
        "outputId": "e66bf9f8-9296-4d6d-ddfa-8ff9419360ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#append all folds in one single vector.\n",
        "all_split_results = []\n",
        "all_stem_results = []\n",
        "for m in range(len(results_split)):\n",
        "  all_split_results += results_split[m]\n",
        "  all_stem_results += results_with_stemming[m]\n",
        "  \n",
        "p_value = sign_test(all_split_results, all_stem_results)\n",
        "\n",
        "print(\"p_value =\", p_value)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the difference is not significant\n",
            "p_value = 0.9465186089423488346539016590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p8zEMJRsKeln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The results show that adding stemming does not improve the results significantly. One possible reason coul be because the stemmer is not always correct in finding words with similiar stems, and count words with different meanings and maybe even different sentiments as one word. However we supose this would only play a marginal role. \n",
        "However, in both cases a large number of words in the review carry no relenvant meaning for the sentment analisys. Stemming them does not filter them out and our Naive Bayes Classifier is as confused as before when classifing some reviews."
      ]
    },
    {
      "metadata": {
        "id": "JkDHVq_1XUVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Q3.8: What happens to the number of features (i.e., the size of the vocabulary) when using stemming as opposed to (Q3.2)? (0.5pt)\n",
        "Give actual numbers. You can use the held-out training set to determine these."
      ]
    },
    {
      "metadata": {
        "id": "MA3vee5-rJyy",
        "colab_type": "code",
        "outputId": "560d731c-b091-47f1-980c-2bb4beb375b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "review=[]\n",
        "for i in range(0,900):\n",
        "  review.append(reviews[i])\n",
        "for i in range(1000,1900):\n",
        "  review.append(reviews[i])\n",
        "print('Stemming in progress.')\n",
        "vocab_with_stemming = init_dict_with_stemming(review)\n",
        "vocab_without_stemming = init_dict(review)\n",
        "print(\"Size of The Vocabulary Before Stemming:   \",len(vocab_without_stemming))\n",
        "print(\"Size of The Vocabulary After Stemming:   \",len(vocab_with_stemming))\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemming in progress.\n",
            "Size of The Vocabulary Before Stemming:    45348\n",
            "Size of The Vocabulary After Stemming:    32404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GItdrDOBQzsZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It can be seen that stemming has successfuly reduced the number of features by 28%. Which could be interesting when analising larger datasets."
      ]
    },
    {
      "metadata": {
        "id": "SoazfxbNV5Lq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Q3.9: Putting some word order back in (0.5+0.5pt=1pt)\n",
        "\n",
        "A simple way of retaining some of the word\n",
        "order information when using bag-of-words representations is to add **n-grams** features. \n",
        "Retrain your classifier from (Q3.4) using **unigrams+bigrams** and\n",
        "**unigrams+bigrams+trigrams** as features, and report accuracy and statistical significances (in comparison to the experiment at (Q3.4) for all 10 folds, and between the new systems).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "aY3T0JEZWSUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DESIGN CHOICE:**\n",
        "When going through the reviews, we count the ending character of each sentence and the begining of the next sentence as a n-gram. Thus we are considering our sentences to be related in a review."
      ]
    },
    {
      "metadata": {
        "id": "eYuKMTOpq9jz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##necessary functions\n",
        "\n",
        "def init_dict_ngram(reviews):\n",
        "  #makes a dictionary of unigrams, a dictionary of bigrams and a dictionary of trigrams\n",
        "  w_dict = {} #count the number of times each word appears in each class \n",
        "  bigram_dict={}\n",
        "  trigram_dict={}\n",
        "  for r in range(len(reviews)):\n",
        "    word = ['', '', '']             # word = [word, prev word, prev prev word]\n",
        "    count = 0\n",
        "    p = count\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word[p], pos_tag in sentence:\n",
        "        word[p] = word[p].lower()\n",
        "        w_dict[word[p]] = [0, 0]          # [NEGATIVE class, POSITIVE class]\n",
        "        bigram = str(word[p-1] + word[p]) # prev_word + word\n",
        "        bigram_dict[bigram] = [0, 0]      # [NEGATIVE class, POSITIVE class]\n",
        "        trigram = str(word[p-2] + bigram) # prev_prev_word + prev_word + word\n",
        "        trigram_dict[trigram] = [0, 0]    # [NEGATIVE class, POSITIVE class]\n",
        "        count += 1\n",
        "        p = count%3\n",
        "  return w_dict, bigram_dict, trigram_dict\n",
        "\n",
        "\n",
        "def count_ngram(reviews, index):\n",
        "  #takes a set of reviews, makes ngrams, and counts unigrams and ngrams. \n",
        "  #'ngram'_frequency: dictionary with the count of each word\n",
        "  #'ngram'V_frequency: stores the total times all the 'ngrams' were used in each class\n",
        "  \n",
        "  word_frequency, bigram_frequency ,trigram_frequency = init_dict_ngram(reviews)\n",
        "  review_class = 0\n",
        "  #counting loop, storing in each 'ngram'_frequency\n",
        "  for r in index:\n",
        "    count=0\n",
        "    if (reviews[r][\"sentiment\"] == 'NEG'):\n",
        "      review_class = 0\n",
        "    else:\n",
        "      review_class = 1\n",
        "    for sentence in reviews[r][\"content\"]:\n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        word_frequency[word][review_class] += 1\n",
        "        if count >=2:\n",
        "          Ngram=str(prev_word+word)\n",
        "          bigram_frequency[Ngram][review_class] += 1\n",
        "          Ngram=str(prev_prev_word+prev_word+word)\n",
        "          trigram_frequency[Ngram][review_class] += 1\n",
        "          prev_prev_word=prev_word\n",
        "        elif count == 1:\n",
        "          Ngram=str(prev_word+word)\n",
        "          bigram_frequency[Ngram][review_class] += 1\n",
        "          prev_prev_word=prev_word\n",
        "        count +=1\n",
        "        prev_word=word      \n",
        "  \n",
        "  #summing the counts, making 'ngram'V_frequencies\n",
        "  vocab_frequency = [0, 0] #vocab frequency:stores the total times all the words used in each class\n",
        "  biV_frequency=[0,0]      #bigram vocab frequency\n",
        "  triV_frequency=[0,0]     #trigram vocab frequency\n",
        "  for word in word_frequency: \n",
        "    vocab_frequency[0] += word_frequency[word][0] #negative class\n",
        "    vocab_frequency[1] += word_frequency[word][1] #positive class\n",
        "  for ngram in bigram_frequency:\n",
        "    biV_frequency[0] += bigram_frequency[ngram][0] #negative class\n",
        "    biV_frequency[1] += bigram_frequency[ngram][1] #positive class\n",
        "  for ngram in trigram_frequency:\n",
        "    triV_frequency[0] += trigram_frequency[ngram][0] #negative class\n",
        "    triV_frequency[1] += trigram_frequency[ngram][1] #positive class\n",
        "      \n",
        "  return vocab_frequency, word_frequency,biV_frequency,bigram_frequency, triV_frequency,trigram_frequency\n",
        "\n",
        "\n",
        "def training_ngram(w_dic,index, reviews, negative_size, vocab_frequency, word_frequency):\n",
        "  # trains the NB_classifier\n",
        "  prob_word_given_class = word_probability(w_dic,\n",
        "                                           vocab_frequency, \n",
        "                                           word_frequency)\n",
        "  \n",
        "  prob_class = class_probability(index, negative_size)\n",
        "\n",
        "  ln_p_class, ln_p_word_g_class = log_probabilities(prob_class,\n",
        "                                                    word_frequency,\n",
        "                                                    prob_word_given_class,\n",
        "                                                    w_dic)\n",
        "  return  ln_p_class, ln_p_word_g_class\n",
        "\n",
        "def classify_ngram(num_ngram,ln_p_class, ln_p_word_g_class,ln_p_bigram_g_class,ln_p_trigram_g_class, test_set_i, reviews):\n",
        "  # ^c = argmax [ln(prob_class(c) + sum(prob_word_in_class)]\n",
        "  \n",
        "  #switches, deciding what degree of ngrams is being considered\n",
        "  if num_ngram == 0:\n",
        "    bigram_switch = False\n",
        "    trigram_switch = False\n",
        "  if num_ngram == 1:\n",
        "    bigram_switch = True\n",
        "    trigram_switch = False\n",
        "  if num_ngram == 2:\n",
        "    bigram_switch = True\n",
        "    trigram_switch = True\n",
        "  \n",
        "  #looping over the test reviews, counting over each dictionary and calculating the overall probabilities\n",
        "  NB_classifier = []\n",
        "  for r in test_set_i:\n",
        "    count=0\n",
        "    n_or_p = [ln_p_class[0] , ln_p_class[1]]\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        #checks if word is in the negative class\n",
        "        if ln_p_word_g_class[word][0] < 0: \n",
        "          n_or_p[0] += ln_p_word_g_class[word][0]\n",
        "        #checks if word was used in the positive class\n",
        "        if ln_p_word_g_class[word][1] < 0: \n",
        "          n_or_p[1] += ln_p_word_g_class[word][1]\n",
        "        \n",
        "        if bigram_switch:\n",
        "          if count>=1:\n",
        "            Ngram=str(prev_word_b+word)\n",
        "            #checks if bigram is in the negative class\n",
        "            if ln_p_bigram_g_class[Ngram][0] < .5: \n",
        "               n_or_p[0] += ln_p_bigram_g_class[Ngram][0]\n",
        "            #checks if bigram was used in the positive class\n",
        "            if ln_p_bigram_g_class[Ngram][1] < .5: \n",
        "               n_or_p[1] += ln_p_bigram_g_class[Ngram][1]\n",
        "            #update\n",
        "            prev_word_b=word\n",
        "          else:\n",
        "            prev_word_b=word\n",
        "           \n",
        "        if trigram_switch:\n",
        "          if count>=2:\n",
        "            Ngram=str(prev_prev_word+prev_word+word)\n",
        "            #checks if trigram is in the negative class\n",
        "            if ln_p_trigram_g_class[Ngram][0] < .5: \n",
        "               n_or_p[0] += ln_p_trigram_g_class[Ngram][0]\n",
        "            #checks if trigram was used in the positive class\n",
        "            if ln_p_trigram_g_class[Ngram][1] < .5: \n",
        "               n_or_p[1] += ln_p_trigram_g_class[Ngram][1]\n",
        "            #update\n",
        "            prev_prev_word=prev_word\n",
        "            prev_word=word\n",
        "          if count==0:\n",
        "            prev_word=word\n",
        "          if count==1:\n",
        "            prev_prev_word=prev_word\n",
        "            prev_word=word\n",
        "        count +=1  \n",
        "       \n",
        "    if (n_or_p[0] >= n_or_p[1]):\n",
        "      NB_classifier.append([0,r]) # classified as negative\n",
        "    else: \n",
        "      NB_classifier.append([1,r]) # classified as positive\n",
        "  return NB_classifier\n",
        "\n",
        " \n",
        "def cross_validation_ngram(num_ngram):\n",
        "  #cross validation\n",
        "  mod=10\n",
        "  results_ngram = []\n",
        "  splits = round_robin_split(reviews, mod = 10)\n",
        "  negative_sizes = nr_negative (reviews, splits)\n",
        "\n",
        "  for m in range(mod):\n",
        "    #Training\n",
        "    train_set_i, test_set_i, negative_size = train_test_sets(splits,\n",
        "                                                             m,\n",
        "                                                             negative_sizes)\n",
        "\n",
        "    vocab_frequency, word_frequency, biV_frequency, bigram_frequency, triV_frequency, trigram_frequency = count_ngram(reviews, train_set_i)\n",
        "\n",
        "    smooth_switch = True\n",
        "    if smooth_switch:\n",
        "      vocab_frequency, word_frequency = smoothing(vocab_frequency,\n",
        "                                                  word_frequency)\n",
        "      biV_frequency, bigram_frequency = smoothing(biV_frequency,\n",
        "                                                  bigram_frequency)\n",
        "      triV_frequency, trigram_frequency = smoothing(triV_frequency,\n",
        "                                                  trigram_frequency)\n",
        "\n",
        "    w_dict, bigram_dict, trigram_dict = init_dict_ngram(reviews)\n",
        "    \n",
        "    #calculating log probabilities \n",
        "    if num_ngram == 0 or num_ngram == 1 or num_ngram == 2:    #for single words\n",
        "      ln_p_class, ln_p_word_g_class = training_ngram(w_dict,train_set_i,\n",
        "                                                     reviews,\n",
        "                                                     negative_size, \n",
        "                                                     vocab_frequency,\n",
        "                                                     word_frequency)\n",
        "    if num_ngram == 1 or num_ngram == 2:           #for a sequence of two words\n",
        "      ln_p_class, ln_p_bigram_g_class = training_ngram(bigram_dict,train_set_i,\n",
        "                                                     reviews,\n",
        "                                                     negative_size, \n",
        "                                                     biV_frequency,\n",
        "                                                     bigram_frequency)\n",
        "    if num_ngram == 2:        #for a sequence of 3 words\n",
        "      ln_p_class, ln_p_trigram_g_class = training_ngram(trigram_dict,train_set_i,\n",
        "                                                     reviews,\n",
        "                                                     negative_size, \n",
        "                                                     triV_frequency,\n",
        "                                                     trigram_frequency)\n",
        "    \n",
        "    if num_ngram !=2:      #to avoid referencing them in the NB_classifier function without initialization\n",
        "      ln_p_trigram_g_class=[]\n",
        "    if num_ngram==0:\n",
        "      ln_p_bigram_g_class=[]\n",
        "      \n",
        "    #Test Classifier:\n",
        "    NB_classifier = classify_ngram(num_ngram,ln_p_class,\n",
        "                             ln_p_word_g_class,\n",
        "                             ln_p_bigram_g_class,\n",
        "                             ln_p_trigram_g_class,\n",
        "                             test_set_i,\n",
        "                             reviews)\n",
        "    #print(NB_classifier)\n",
        "    results_ngram.append(evaluate_NB_classifier(NB_classifier, \n",
        "                                                       test_set_i, \n",
        "                                                       reviews))\n",
        "\n",
        "    print(m,\") acuracy: \", \n",
        "          sum(results_ngram[m])/len(results_ngram[m]))\n",
        "    \n",
        "  return results_ngram,w_dict, bigram_dict, trigram_dict\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y0zvASLGobmk",
        "colab_type": "code",
        "outputId": "454df079-99a9-4a17-9da0-b5125b0a20e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "cell_type": "code",
      "source": [
        "##calculating the results\n",
        "\n",
        "print(\"Using bigrams + unigrams:\")\n",
        "results_bigram,w_dict, bigram_dict, trigram_dict = cross_validation_ngram(1)\n",
        "bigrams_NB = report_fold_performance(results_bigram, print_performance = True)\n",
        "\n",
        "print(\"Using trigrams + bigrams + unigrams:\")\n",
        "results_trigram,w_dict, bigram_dict, trigram_dict = cross_validation_ngram(2)\n",
        "trigrams_NB = report_fold_performance(results_trigram, print_performance = True)\n",
        "\n",
        "#add mean and variance for each one\n",
        "#print what which one is doing"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using bigrams + unigrams:\n",
            "0 ) acuracy:  0.795\n",
            "1 ) acuracy:  0.87\n",
            "2 ) acuracy:  0.835\n",
            "3 ) acuracy:  0.88\n",
            "4 ) acuracy:  0.805\n",
            "5 ) acuracy:  0.865\n",
            "6 ) acuracy:  0.835\n",
            "7 ) acuracy:  0.83\n",
            "8 ) acuracy:  0.855\n",
            "9 ) acuracy:  0.84\n",
            "Mean performance:  0.841 \n",
            " Variance: 0.0006739999999999994\n",
            "Using trigrams + bigrams + unigrams:\n",
            "0 ) acuracy:  0.795\n",
            "1 ) acuracy:  0.89\n",
            "2 ) acuracy:  0.855\n",
            "3 ) acuracy:  0.865\n",
            "4 ) acuracy:  0.795\n",
            "5 ) acuracy:  0.89\n",
            "6 ) acuracy:  0.835\n",
            "7 ) acuracy:  0.835\n",
            "8 ) acuracy:  0.875\n",
            "9 ) acuracy:  0.845\n",
            "Mean performance:  0.8480000000000001 \n",
            " Variance: 0.0010559999999999996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SJeCG9gY464B",
        "colab_type": "code",
        "outputId": "1ad0c077-803a-479f-ab98-f903628961e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "cell_type": "code",
      "source": [
        "##calculating p-values\n",
        "\n",
        "#append all folds in one single vector.\n",
        "all_split_results = []\n",
        "all_bigram_results = []\n",
        "all_trigram_results = []\n",
        "for m in range(len(results_split)):\n",
        "  all_split_results += results_split[m]\n",
        "  all_bigram_results += results_bigram[m]\n",
        "  all_trigram_results += results_trigram[m]\n",
        "\n",
        "print(\"NB using only unigrams and NB using unigrams+bigrams:\")\n",
        "p_value_bigram_split = sign_test(all_split_results, all_bigram_results)\n",
        "print(\"p_value =\", p_value_bigram_split)\n",
        "print(\"\")\n",
        "\n",
        "print(\"NB using only unigrams and NB using unigrams+bigrams + trigrams:\")\n",
        "p_value_trigram_split = sign_test(all_split_results, all_trigram_results)\n",
        "print(\"p_value =\", p_value_trigram_split)\n",
        "print(\"\")\n",
        "\n",
        "print(\"NB using unigrams+bigrams and NB using unigrams+bigrams + trigrams:\")\n",
        "p_value_trigram_bigram_split = sign_test(all_bigram_results, all_trigram_results)\n",
        "print(\"p_value =\", p_value_trigram_bigram_split)\n",
        "print(\"\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB using only unigrams and NB using unigrams+bigrams:\n",
            "the difference is not significant\n",
            "p_value = 0.2932785698870256137209886960\n",
            "\n",
            "NB using only unigrams and NB using unigrams+bigrams + trigrams:\n",
            "the difference is not significant\n",
            "p_value = 0.1725517183477154341914779742\n",
            "\n",
            "NB using unigrams+bigrams and NB using unigrams+bigrams + trigrams:\n",
            "the difference is not significant\n",
            "p_value = 0.7712977979137471160722421800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dVrGGArkrWoL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Q3.10: How many features does the BoW model have to take into account now? (0.5pt)\n",
        "How does this number compare (e.g., linear, square, cubed, exponential) to the number of features at (Q3.8)? \n",
        "\n",
        "Use the held-out training set once again for this.\n"
      ]
    },
    {
      "metadata": {
        "id": "_z8sAJeUrdtM",
        "colab_type": "code",
        "outputId": "6e5b70c9-35ba-4456-8003-dd6590188bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "review=[]\n",
        "for i in range(0,900):\n",
        "  review.append(reviews[i])\n",
        "for i in range(1000,1900):\n",
        "  review.append(reviews[i])\n",
        "\n",
        "vocab_with_stemming = init_dict_with_stemming(review)\n",
        "vocab_without_stemming=init_dict(review)\n",
        "#w_dict, bigram_dict, trigram_dict=init_dict_ngram(review)\n",
        "size_trigram=len(w_dict)+len(bigram_dict)+len(trigram_dict)\n",
        "size_bigram=len(w_dict)+len(bigram_dict)\n",
        "print(\"Size of The Vocabulary Before Stemming:   \",len(vocab_without_stemming))\n",
        "print(\"Size of The Vocabulary After Stemming:   \",len(vocab_with_stemming))\n",
        "print(\"Size of the Vocabulary For unigrams + bigrams:\", size_bigram)\n",
        "print(\"Size of the Vocabulary For unigrams + bigrams + trigrams:\", size_trigram)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of The Vocabulary Before Stemming:    45348\n",
            "Size of The Vocabulary After Stemming:    32404\n",
            "Size of the Vocabulary For unigrams + bigrams: 508308\n",
            "Size of the Vocabulary For unigrams + bigrams + trigrams: 1549499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BwogZAyk28QD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The size of vocabuary after adding bigrams is approximateley 15 times the size of vocabulary for just unigrams. Also, the size of vocabulary after adding trigrams is in the order of three times the size of vocabulary before adding them (just unigrams and bigrams).\n",
        "\n",
        "\n",
        "> \n",
        "It should be mentioned that if we had a close to infinite corpus, where there are all word combinations. Then, if we consider the number of unigrams to be N, the size of the vocabulary would increase by $N^2$ if we add bigrams, and again, if we add the trigrams, $N^3$. But here, since the size of our review set is small, we cannot see the full effect of adding n-grams on the length of vocabulary. In short we were expecting an exponential relationship between vocabulary size and n-grams. In practice we seem experienced some sort of polinomial increase due to some word combinations never happening in the corpus."
      ]
    },
    {
      "metadata": {
        "id": "CHWKDL3YV6vh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machines (4pts)\n"
      ]
    },
    {
      "metadata": {
        "id": "hJSYhcVaoJGt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Though simple to understand, implement, and debug, one\n",
        "major problem with the Naive Bayes classifier is that its performance\n",
        "deteriorates (becomes skewed) when it is being used with features which\n",
        "are not independent (i.e., are correlated). Another popular classifier\n",
        "that doesn’t scale as well to big data, and is not as simple to debug as\n",
        "Naive Bayes, but that doesn’t assume feature independence is the Support\n",
        "Vector Machine (SVM) classifier.\n",
        "\n",
        "You can find more details about SVMs in Chapter 7 of Bishop: Pattern Recognition and Machine Learning.\n",
        "Other sources for learning SVM:\n",
        "* http://web.mit.edu/zoya/www/SVM.pdf\n",
        "* http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf\n",
        "* https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Use the scikit-learn implementation of \n",
        "[SVM.](http://scikit-learn.org/stable/modules/svm.html) with the default parameters.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0LnzNtQBV8gr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q4.1): Train SVM and compare to Naive Bayes (2pt)\n",
        "\n",
        "Train an SVM classifier (sklearn.svm.LinearSVC) using your features. Compare the\n",
        "classification performance of the SVM classifier to that of the Naive\n",
        "Bayes classifier from (Q3.4) and report the numbers.\n",
        "Do cross validation and concatenate the predictions from all folds to compute the significance.  Are the results significantly better?\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JBscui8Mvoz0",
        "colab_type": "code",
        "outputId": "3f7ad6fa-3e18-4e38-87d0-c3eed9ca6259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def super_bag_of_words(reviews, train_set_i):\n",
        "  w_dict = {}      \n",
        "  bigram_dict={}\n",
        "  trigram_dict={}\n",
        "  for r in train_set_i:\n",
        "    word = ['', '', '']             # word = [word, prev word, prev prev word]\n",
        "    count = 0\n",
        "    p = count\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word[p], pos_tag in sentence:\n",
        "        word[p] = word[p].lower()\n",
        "        w_dict[word[p]] = 0               # [NEGATIVE class, POSITIVE class]\n",
        "        bigram = str(word[p-1] + word[p]) # prev_word + word\n",
        "        bigram_dict[word[p]] = 0\n",
        "        bigram_dict[bigram] = 0           # [NEGATIVE class, POSITIVE class]\n",
        "        trigram = str(word[p-2] + bigram) # prev_prev_word + prev_word + word\n",
        "        trigram_dict[word[p]] = 0\n",
        "        trigram_dict[bigram] = 0  \n",
        "        trigram_dict[trigram] = 0         # [NEGATIVE class, POSITIVE class]\n",
        "        count += 1\n",
        "        p = count%3\n",
        "  for n_dict in [w_dict, bigram_dict, trigram_dict]:\n",
        "    index = 0\n",
        "    for word in n_dict:\n",
        "      n_dict[word] = index\n",
        "      index += 1\n",
        "  return  w_dict, bigram_dict, trigram_dict\n",
        "\n",
        "def make_feature_vector(reviews, w_dict, n):\n",
        "  feature_vectors = np.zeros((len(reviews), len(w_dict))) \n",
        "  for r in range(len(reviews)):\n",
        "    word = [\"\",\"\",\"\"]\n",
        "    count = 0\n",
        "    p = count\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word[p], pos_tag in sentence:\n",
        "        word[p] = word[p].lower()\n",
        "        tri_gram= str(word[p-2] + word[p-1] + word[p])\n",
        "        bi_gram = str(word[p-1] + word[p])\n",
        "        for w in [word[p], bi_gram, tri_gram]:\n",
        "          ungly_counter = 0\n",
        "          if w in w_dict:\n",
        "            ind = w_dict[w] \n",
        "            feature_vectors[r][ind] += 1\n",
        "            ungly_counter += 1\n",
        "            # that is necessary to make sure the word won't be added multiple \n",
        "            # times for bi-grams and unigrams.\n",
        "            if ungly_counter >= n:\n",
        "              break\n",
        "        count += 1\n",
        "        p = count%n\n",
        "  return feature_vectors\n",
        "\n",
        "def label_my_data(reviews):\n",
        "  label = np.zeros(len(reviews), dtype= int)\n",
        "  for r in range(len(reviews)):\n",
        "    if reviews[r]['sentiment'] == 'POS':\n",
        "      label[r] = 1\n",
        "  return label\n",
        "\n",
        "def evaluate_SVM_classifier(classifier, test_set_i, reviews):\n",
        "  results = np.zeros(len(test_set_i)) # 1 -> correctly evaluated, 0 -> falsely evaluated\n",
        "  c = 0\n",
        "  for i in test_set_i:\n",
        "    if (reviews[i][\"sentiment\"] == \"NEG\" and classifier[c] == 0) or (reviews[i][\"sentiment\"] == \"POS\" and classifier[c] == 1):\n",
        "      results[c] = 1\n",
        "    c += 1\n",
        "  return results\n",
        "\n",
        "\n",
        "def cross_validation_SVM(reviews, label, n):\n",
        "  # cross validation training of SVM\n",
        "  mod = 10\n",
        "  splits = round_robin_split(reviews, mod = 10)\n",
        "  negative_sizes = nr_negative (reviews, splits)\n",
        "  results_split_SVM = []\n",
        "\n",
        "  # fold training:\n",
        "  for m in range(mod):\n",
        "    \n",
        "\n",
        "    train_set_i, test_set_i, negative_size = train_test_sets(splits, \n",
        "                                                             m, \n",
        "                                                             negative_sizes)\n",
        "    \n",
        "\n",
        "    word_dict, bi_dict, tri_dict = super_bag_of_words(reviews, train_set_i)\n",
        "    all_dicts = [word_dict, bi_dict, tri_dict]\n",
        "    feature_vectors = make_feature_vector(reviews, all_dicts[n-1], n)\n",
        "    \n",
        "    fv = [] # feature vectors used in this fold\n",
        "    l = []  # labels for this fold\n",
        "    for i in train_set_i:\n",
        "      fv.append(feature_vectors[i])\n",
        "      l.append(label[i])\n",
        "\n",
        "    # The magical Suport Vector Machine trainer:\n",
        "    clf = svm.LinearSVC()\n",
        "    clf.fit(fv, l) \n",
        "    \n",
        "    t_fv = []\n",
        "    for i in test_set_i:\n",
        "      t_fv.append(feature_vectors[i])\n",
        "    \n",
        "    SVM_classification = clf.predict(t_fv)\n",
        "    \n",
        "    results_split_SVM.append(evaluate_SVM_classifier(SVM_classification, \n",
        "                                                    test_set_i, \n",
        "                                                    reviews))\n",
        "    \n",
        "    print(m,\") acuracy: \", sum(results_split_SVM[m])/len(results_split_SVM[m]))\n",
        "  return results_split_SVM\n",
        "\n",
        "label = label_my_data(reviews)\n",
        "\n",
        "print(\"word features\")\n",
        "results_split_SVM = cross_validation_SVM(reviews, label, 1)\n",
        "SVM_word = report_fold_performance(results_split_SVM, print_performance = True)\n",
        "\n",
        "#For curiosity reasons:\n",
        "#print(\"\\n unigrams and bi-grams\")\n",
        "#results_split_SVM_bigrams = cross_validation_SVM(reviews, label, 2)\n",
        "#_ = report_fold_performance(results_split_SVM_bigrams, print_performance = True)\n",
        "\n",
        "#print(\"\\n unigrams, bigrams and trigrams\")\n",
        "#results_split_SVM_trigrams = cross_validation_SVM(reviews, label, 3)\n",
        "#_ = report_fold_performance(results_split_SVM_trigrams, print_performance = True)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word features\n",
            "0 ) acuracy:  0.81\n",
            "1 ) acuracy:  0.795\n",
            "2 ) acuracy:  0.8\n",
            "3 ) acuracy:  0.84\n",
            "4 ) acuracy:  0.85\n",
            "5 ) acuracy:  0.815\n",
            "6 ) acuracy:  0.845\n",
            "7 ) acuracy:  0.85\n",
            "8 ) acuracy:  0.875\n",
            "9 ) acuracy:  0.84\n",
            "Mean performance:  0.8320000000000001 \n",
            " Variance: 0.0005959999999999991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XlIJnFOYzC8a",
        "colab_type": "code",
        "outputId": "5b2130ae-2055-4162-81ae-1793dfeec0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "##calculating p-values\n",
        "\n",
        "#append all folds in one single vector.\n",
        "all_results_split_SVM = np.array([])\n",
        "all_results_split = []\n",
        "for m in range(len(results_split)):\n",
        "  all_results_split_SVM = np.concatenate((all_results_split_SVM, results_split_SVM[m]))\n",
        "  all_results_split += results_split[m]\n",
        "\n",
        "p_value = sign_test(all_results_split_SVM, all_results_split)\n",
        "print(\"Comparison SVM and NB for word features:\")\n",
        "print(\"p_value =\", p_value)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the difference is not significant\n",
            "Comparison SVM and NB for word features:\n",
            "p_value = 0.5166977962573607869966679093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ili4oIev2pTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We would like to point out that we are comparing the Naive Bayes classifier using word features with the SVM also using word features. The importance fair comparison was stressed by one of the teacher assistents in Piazza. For our disapointment, the difference between NB and SVM is not relevant."
      ]
    },
    {
      "metadata": {
        "id": "ifXVWcK0V9qY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### More linguistics\n",
        "\n",
        "Now add in part-of-speech features. You will find the\n",
        "movie review dataset has already been POS-tagged for you. Try to\n",
        "replicate what Pang et al. were doing:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xA3I82o4oWGu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####(Q4.2) Replace your features with word+POS features, and report performance with the SVM. Does this help? Do cross validation and concatenate the predictions from all folds to compute the significance. Are the results significant? Why?  (1pt)\n"
      ]
    },
    {
      "metadata": {
        "id": "DALZQlafZMrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DESIGN CHOICE:** We are using tuples (word, POS) as  inputs to the vocabulary."
      ]
    },
    {
      "metadata": {
        "id": "NOvjYe-t2Br6",
        "colab_type": "code",
        "outputId": "de835a85-b9c7-4dff-d448-eee63212a064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "cell_type": "code",
      "source": [
        "def super_bag_of_words_POS(reviews, train_set_i):\n",
        "  '''Creates a bag of words for all the words in the training set.\n",
        "  Inputs:\n",
        "    reviews: the reviews in the format given in the exercise\n",
        "    train_set_i: vector of indexes of the reviews of the trainin set\n",
        "  Return:\n",
        "    dictionary of the format {(word,POS tag) : index}\n",
        "    example {(dog, verb): 1243554, (dog, noun): 33333}\n",
        "  '''\n",
        "  w_dict = {} \n",
        "  for r in train_set_i:\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        w_dict[(word,pos_tag)] = 0 \n",
        "  index = 0\n",
        "  for (word,pos_tag) in w_dict:\n",
        "    w_dict[(word,pos_tag)] = index\n",
        "    index += 1\n",
        "  return w_dict\n",
        "           \n",
        "def make_feature_vector_POS(reviews, word_dict):\n",
        "  feature_vectors = [] \n",
        "  for r in range(len(reviews)):\n",
        "    review_vector = [0]*len(word_dict)\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        word = word.lower()\n",
        "        if (word,pos_tag) in word_dict:\n",
        "          ind = word_dict[(word,pos_tag)] \n",
        "          review_vector[ind] += 1\n",
        "    feature_vectors.append(review_vector)\n",
        "  return feature_vectors   \n",
        "           \n",
        "def cross_validation_SVM_POS(reviews, label):\n",
        "  # cross validation training of SVM\n",
        "  mod = 10\n",
        "  splits = round_robin_split(reviews, mod = 10)\n",
        "  negative_sizes = nr_negative (reviews, splits)\n",
        "  results_split_SVM = []\n",
        "\n",
        "  # fold training:\n",
        "  for m in range(mod):\n",
        "\n",
        "    train_set_i, test_set_i, negative_size = train_test_sets(splits, \n",
        "                                                             m, \n",
        "                                                             negative_sizes)\n",
        "    \n",
        "    word_dict = super_bag_of_words_POS(reviews, train_set_i)\n",
        "    \n",
        "    feature_vectors = make_feature_vector_POS(reviews, word_dict)\n",
        "    \n",
        "    \n",
        "    fv = [] # feature vectors used in this fold\n",
        "    l = []  # labels for this fold\n",
        "    for i in train_set_i:\n",
        "      fv.append(feature_vectors[i])\n",
        "      l.append(label[i])\n",
        "\n",
        "    # The magical Suport Vector Machine trainer:\n",
        "    clf = svm.LinearSVC()\n",
        "    clf.fit(fv, l) \n",
        "    \n",
        "    t_fv = []\n",
        "    for i in test_set_i:\n",
        "      t_fv.append(feature_vectors[i])\n",
        "    \n",
        "    SVM_classification = clf.predict(t_fv)\n",
        "\n",
        "    results_split_SVM.append(evaluate_SVM_classifier(SVM_classification, \n",
        "                                                    test_set_i, \n",
        "                                                    reviews))\n",
        "\n",
        "    # 3- check accuracy and compute significance by use of the sign-test\n",
        "\n",
        "    print(m,\") acuracy: \", sum(results_split_SVM[m])/len(results_split_SVM[m]))\n",
        "  return results_split_SVM\n",
        "\n",
        "label = label_my_data(reviews)\n",
        "results_split_SVM_POS = cross_validation_SVM_POS(reviews, label)\n",
        "SVM_wp = report_fold_performance(results_split_SVM_POS, print_performance = True)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 ) acuracy:  0.82\n",
            "1 ) acuracy:  0.795\n",
            "2 ) acuracy:  0.825\n",
            "3 ) acuracy:  0.84\n",
            "4 ) acuracy:  0.84\n",
            "5 ) acuracy:  0.845\n",
            "6 ) acuracy:  0.855\n",
            "7 ) acuracy:  0.855\n",
            "8 ) acuracy:  0.865\n",
            "9 ) acuracy:  0.84\n",
            "Mean performance:  0.8380000000000001 \n",
            " Variance: 0.0003709999999999997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ekwla4qwl_Il",
        "colab_type": "code",
        "outputId": "bd63b5a9-510d-4989-e91e-ac6267c605be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#append all folds in one single vector.\n",
        "all_results_split_SVM_POS = np.array([])\n",
        "for m in range(len(results_split)):\n",
        "  all_results_split_SVM_POS = np.concatenate((all_results_split_SVM_POS, \n",
        "                                              results_split_SVM_POS[m]))\n",
        "\n",
        "p_value = sign_test(all_results_split_SVM, all_results_split_SVM_POS)\n",
        "\n",
        "print(\"p_value =\", p_value)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the difference is not significant\n",
            "p_value = 0.8057148676803825624105038557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dcc0e3vvfJHe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are comparing two SVMs, one using the word features and the second using the tuples word POS tags as features. However the difference in performance is not significant. Intuitively, that makes sense. The POS tags do not carry any information about the meaning of the word, only about the grammatical role of that word in that sentence. Therefore they do not help to extract the meaning or the sentiment of the word.\n"
      ]
    },
    {
      "metadata": {
        "id": "Su-3w87eMW0w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### (Q4.3) Discard all closed-class words from your data (keep only nouns (N*), verbs (V*), adjectives (J*) and adverbs (RB*)), and report performance. Does this help? Do cross validation and concatenate the predictions from all folds to compute the significance. Are the results significantly better than when we don't discard the closed-class words? Why? (1pt)"
      ]
    },
    {
      "metadata": {
        "id": "CCUPlPozCYUX",
        "colab_type": "code",
        "outputId": "bdcc4e59-80ae-494c-b6d4-483313ba293f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "cell_type": "code",
      "source": [
        "def bag_of_words_POS_without_clossed_class(reviews, train_set_i):\n",
        "  w_dict = {} #count the number of times each word appears in each class \n",
        "  for r in train_set_i:\n",
        "    # loops through all reviews and add the words to the dict.\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        if pos_tag[0] in 'NVJ' or pos_tag[0:1]=='RB':\n",
        "          word = word.lower()\n",
        "          w_dict[(word, pos_tag)] = 0 \n",
        "  index = 0\n",
        "  for (word,pos_tag) in w_dict:\n",
        "    w_dict[(word, pos_tag)] = index\n",
        "    index += 1\n",
        "  return w_dict\n",
        "\n",
        "def make_feature_vector_POS_without_clossed_class(reviews,word_dict):\n",
        "  feature_vectors = [] # np.zeros([len(reviews),len(word_dict)])\n",
        "  for r in range(len(reviews)):\n",
        "    review_vector = [0]*len(word_dict)\n",
        "    for sentence in reviews[r][\"content\"]: \n",
        "      for word, pos_tag in sentence:\n",
        "        if pos_tag[0] in 'NVJ' or pos_tag[0:1]=='RB': \n",
        "          word = word.lower()\n",
        "          if (word,pos_tag) in word_dict:\n",
        "            ind = word_dict[(word,pos_tag)]\n",
        "            review_vector[ind] += 1\n",
        "    feature_vectors.append(review_vector)\n",
        "  return feature_vectors \n",
        "\n",
        "def cross_validation_SVM_POS_without_clossed_class(reviews, label):\n",
        "  # cross validation training of SVM\n",
        "  mod = 10\n",
        "  splits = round_robin_split(reviews, mod = 10)\n",
        "  negative_sizes = nr_negative (reviews, splits)\n",
        "  results_split_SVM = []\n",
        "\n",
        "  # fold training:\n",
        "  for m in range(mod):\n",
        "\n",
        "    train_set_i, test_set_i, negative_size = train_test_sets(splits, \n",
        "                                                             m, \n",
        "                                                             negative_sizes)\n",
        "    \n",
        "    word_dict = bag_of_words_POS_without_clossed_class(reviews, train_set_i)\n",
        "    \n",
        "    feature_vectors = make_feature_vector_POS_without_clossed_class(reviews, \n",
        "                                                                    word_dict)\n",
        "    \n",
        "    \n",
        "    fv = [] # feature vectors used in this fold\n",
        "    l = []  # labels for this fold\n",
        "    for i in train_set_i:\n",
        "      fv.append(feature_vectors[i])\n",
        "      l.append(label[i])\n",
        "\n",
        "    # The magical Suport Vector Machine trainer:\n",
        "    clf = svm.LinearSVC()\n",
        "    clf.fit(fv, l) \n",
        "    \n",
        "    t_fv = []\n",
        "    for i in test_set_i:\n",
        "      t_fv.append(feature_vectors[i])\n",
        "    \n",
        "    SVM_classification = clf.predict(t_fv)\n",
        "\n",
        "    results_split_SVM.append(evaluate_SVM_classifier(SVM_classification, \n",
        "                                                    test_set_i, \n",
        "                                                    reviews))\n",
        "\n",
        "    # 3- check accuracy and compute significance by use of the sign-test\n",
        "\n",
        "    print(m,\") acuracy: \", sum(results_split_SVM[m])/len(results_split_SVM[m]))\n",
        "  return results_split_SVM\n",
        "\n",
        "label = label_my_data(reviews)\n",
        "\n",
        "results_split_SVM_POS_without_clossed_class = cross_validation_SVM_POS_without_clossed_class(reviews, label)\n",
        "\n",
        "SVM_sw = report_fold_performance(results_split_SVM_POS_without_clossed_class, print_performance = True)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 ) acuracy:  0.82\n",
            "1 ) acuracy:  0.84\n",
            "2 ) acuracy:  0.81\n",
            "3 ) acuracy:  0.82\n",
            "4 ) acuracy:  0.835\n",
            "5 ) acuracy:  0.86\n",
            "6 ) acuracy:  0.86\n",
            "7 ) acuracy:  0.86\n",
            "8 ) acuracy:  0.87\n",
            "9 ) acuracy:  0.79\n",
            "Mean performance:  0.8365 \n",
            " Variance: 0.0006202499999999995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LwBAWRYtnHoy",
        "colab_type": "code",
        "outputId": "9419644c-c831-4834-b016-76f1a4ae033b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "cell_type": "code",
      "source": [
        "##calculating p-values\n",
        "\n",
        "all_results_split_SVM_POS_without_clossed_class = np.array([])\n",
        "for m in range(len(results_split)):\n",
        "  all_results_split_SVM_POS_without_clossed_class = np.concatenate((all_results_split_SVM_POS_without_clossed_class, \n",
        "                                              results_split_SVM_POS_without_clossed_class[m]))\n",
        "\n",
        "print(\"comparison with and without close clas POS\")\n",
        "p_value = sign_test(all_results_split_SVM_POS_without_clossed_class, all_results_split_SVM_POS)\n",
        "print(\"p_value =\", p_value)\n",
        "\n",
        "print(\"\\ncomparison SVM words features and SVM words + POS\")\n",
        "p_value = sign_test(all_results_split_SVM_POS_without_clossed_class, all_results_split_SVM)\n",
        "\n",
        "print(\"p_value =\", p_value)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comparison with and without close clas POS\n",
            "the difference is not significant\n",
            "p_value = 0.9643397988982472569618317953\n",
            "\n",
            "comparison SVM words features and SVM words + POS\n",
            "the difference is not significant\n",
            "p_value = 0.8580684255496233805937014017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OF1SFPNodyvC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As an attempt to lower the dimension of the feature vectors we discard all words that supposedly carry no relevant meaning for sentiment analysis. That can be seen as striping away dimensions in which the data cannot be linearly separated. That did not help either, which was against our intuition. For instance the words **the** and **a** should have similar distributions regardless of the review being positive or negative, by discarding those words we can reduce our hyperspace to only the relevant dimensions. \n",
        "\n",
        "To explain the lack of statistical significance against the SVM (Q4.1) with word features we go back to the argument that the POS tags do not carry any relevant meaning to the sentiment of the review. Therefore no relevant information is encoded.\n",
        "\n",
        "To explain the lack of statistical significance against the SVM (Q4.2) using *(word, POS tags)* features we can use the argument of if the data is not linearly separable in $n$ dimensions, it will certainly not be in only part of those dimensions.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nfwqOciAl2No",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# (Q8) Discussion (max. 500 words). (5pts)\n",
        "\n",
        "> Based on your experiments, what are the effective features and techniques in sentiment analysis? What information do different features encode?\n",
        "Why is this important? What are the limitations of these features and techniques?\n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "qT2HTmQCQcGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "8d237a54-c664-4e1c-e0e9-75705ccefd98"
      },
      "cell_type": "code",
      "source": [
        "#Plots all the results together for a nice overview =)\n",
        "method = ('Simbolic', 'Naive \\nBayes' ,'smoothed \\nNB', 'NB + \\nstemming', \n",
        "          'NB \\nbigrams', 'NB \\ntrigrams', 'SVM \\nword \\nfeatures', \n",
        "          'SVM \\n(word, POS)', 'SVM \\nfiltered')\n",
        "\n",
        "y_pos = np.arange(len(method))\n",
        "\n",
        "performance = [token_accuracy, \n",
        "               NB_normal, \n",
        "               smoothed_NB[0],\n",
        "               stem_NB[0],\n",
        "               bigrams_NB[0],\n",
        "               trigrams_NB[0],\n",
        "               SVM_word[0],\n",
        "               SVM_wp[0],\n",
        "               SVM_sw[0]]\n",
        " \n",
        "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
        "plt.xticks(y_pos, method)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Method')\n",
        "plt.title('Performance overview of different Sentiment Analysis')\n",
        " \n",
        "plt.show()\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAF+CAYAAACrs5IrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCm8RERGLUXiLiIhYjMJbRETEYv4D0jxuU4ej3r4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f51c718a748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZYuse5WLmekZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This practice was really interesting to experience how rather simple techniques can be quite effective in extracting the overall sentiment of a document. Even bye completely ignoring sentence structure and the relationship between words. \n",
        "\n",
        "1.   *Symbolic approach with sentiment lexicon*. The features aim to encode the sentiment carried by different words in proportion to their count in each review. Sentiment weighting can be included, however, we saw that the unweighted approach is about as effective. It reaches almost 70% accuracy, which is not ideal, but surprisingly good considering the simplicity of the technique. The biggest limitation is we are bounded by the sentiment lexicon. If it is imprecise or has too few words the sentiment extraction may lose a great deal of performance. It also cannot be scaled for other languages. The next two techniques go around this limitation.\n",
        "\n",
        "2.   *Naive Bayes Classifier*. It attempts to capture the sentiment from the choice of words in each review. The features don't take any pre-assigned sentiment to the words. The information encoded by the feature vectors is the likelihood of a word choice given a class. The first surprise was to see that the Naive Bayes classifier performs as bad as a coin toss if no smoothing is used.  \n",
        "\n",
        "      Smoothing takes its accuracy to 82%, which surprised us because the classifier simply ignores the interaction between words. Stemming was used as an attempt to lower the dimensions of the feature vectors. To take the word order in consideration n-grams were also used. None of them showed a significant difference in performance. We were expecting otherwise, as they attempt to capture aspects of the language that the Naive Bayes is ignorant of. \n",
        "      \n",
        "3.   *Support Vector Machines*. This classic machine learning algorithm performed significantly better than Naive Bayes, even though the improvement wasn't impressive considering the increase in algorithm complexity. The features are the word counts themselves. The information encoded by the feature vector is rather abstract. Each feature vector is a point in the vocabulary space and it is assumed it is possible to find a hyperplane that separates the positive reviews from the negative ones.\n",
        "\n",
        "     The features were modified to include the POS tags, however, no improvement was seen. That is expected because the POS tags do not carry any information about the meaning of the word, only about the grammatical role of that word in that sentence. An attempt to lower the dimension of the feature vectors was to discard all words that carry no relevant meaning. That can be seen as striping away dimensions in which the data cannot be linearly separated. That did not help either, which was against our intuition.\n",
        "\n",
        "All techniques and features used share one main limitation. They have no means to take into consideration the context and the relationship between words. They suppose the presence of a set of words is enough to draw relevant conclusions about the overall sentiment of the review. "
      ]
    },
    {
      "metadata": {
        "id": "iwaKwfWQhRk_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submission \n"
      ]
    },
    {
      "metadata": {
        "id": "aOUeaET5ijk-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your names and student numbers here:\n",
        "# Victor Zuanazzi 12325724\n",
        "# Mahsa Mojtahedi 12166510"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3A9K-H6Tii3X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**That's it!**\n",
        "\n",
        "- Check if you answered all questions fully and correctly. \n",
        "- Download your completed notebook using `File -> Download .ipynb` \n",
        "- Also save your notebook as a Github Gist. Get it by choosing `File -> Save as Github Gist`.  Make sure that the gist has a secret link (not public).\n",
        "- Check if your answers are all included in the file you submit (e.g. check the Github Gist URL)\n",
        "- Submit your .ipynb file and link to the Github Gist via *Canvas*. One submission per group. "
      ]
    }
  ]
}